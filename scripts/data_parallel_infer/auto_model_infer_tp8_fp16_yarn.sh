#!/bin/bash
# =======================================================
# åˆ†å¸ƒå¼ vLLM æ¨¡å‹æ¨ç†éƒ¨ç½²è„šæœ¬ï¼ˆé«˜å¹¶å‘ä¼˜åŒ–ç‰ˆï¼‰
# =======================================================
#
# åŠŸèƒ½æè¿°ï¼š
#   1. è·¨å¤šèŠ‚ç‚¹è‡ªåŠ¨éƒ¨ç½² vLLM æ¨¡å‹æœåŠ¡ï¼ˆå•èŠ‚ç‚¹å¤šå¡å¼ é‡å¹¶è¡Œï¼‰
#   2. åŸºäºå¥åº·æ£€æŸ¥ä¸ç«¯å£æ¢æ´»çš„ç¨³å¥å¼å¯åŠ¨ä¸ç›‘æ§
#   3. åŠ¨æ€æ‰¹å¤„ç†ä¸å¹¶è¡Œåº¦å‚æ•°ä¼˜åŒ–ï¼Œæ”¯æŒé«˜å¹¶å‘æ¨ç†
#   4. æ•°æ®æ–‡ä»¶è½®è¯¢åˆ†é…ä¸ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ
#   5. ä¼˜é›…æ¸…ç†ï¼ˆé€€å‡ºä¿¡å·æ•è·ï¼‰ä¸å¤±è´¥å›æ»š
#
# æ ¸å¿ƒç‰¹æ€§ï¼š
#   - è‡ªåŠ¨å‘ç°ä¸åˆ†é…æ•°æ®æ–‡ä»¶ï¼Œæ”¯æŒè‡ªç„¶æ•°å€¼æ’åº
#   - å¤šå±‚æ¬¡å¹¶è¡Œï¼ˆèŠ‚ç‚¹é—´å¹¶è¡Œ + èŠ‚ç‚¹å†…å¤šå¡å¹¶è¡Œ + å•å¡åŠ¨æ€æ‰¹å¤„ç†ï¼‰
#   - æ··åˆå¥åº·æ£€æŸ¥æœºåˆ¶ï¼ˆHTTPæ¢æ´» + æ—¥å¿—æ£€æŸ¥ + è¿›ç¨‹æ£€æŸ¥ï¼‰
#   - åŸºäº PID/æ–‡ä»¶å çš„ä»»åŠ¡ç›‘æ§
#   - å¤±è´¥èŠ‚ç‚¹è‡ªåŠ¨è·³è¿‡ï¼Œåªä½¿ç”¨å¯ç”¨èŠ‚ç‚¹è¿›è¡Œæ¨ç†
#   - èµ„æºé™åˆ¶ä¸ä»»åŠ¡èŠ‚æµ
#
# æ‰§è¡Œæµç¨‹ï¼š
#   1. å‚æ•°æ ¡éªŒä¸ç¯å¢ƒåˆå§‹åŒ–
#   2. è¯»å–èŠ‚ç‚¹åˆ—è¡¨å¹¶ç”Ÿæˆç«¯å£é…ç½®
#   3. å‘ç°æ•°æ®é›†æ–‡ä»¶å¹¶è¿›è¡Œåˆ†é…
#   4. å¹¶è¡Œéƒ¨ç½² vLLM æœåŠ¡å®ä¾‹
#   5. ç­‰å¾…æœåŠ¡å°±ç»ªï¼ˆå¥åº·æ£€æŸ¥ï¼‰å¹¶ç­›é€‰å¯ç”¨èŠ‚ç‚¹
#   6. åˆ†å‘å¹¶å¯åŠ¨æ¨ç†ä»»åŠ¡ï¼ˆæ•°æ®æ–‡ä»¶è½®è¯¢åˆ†é…åˆ°å¯ç”¨èŠ‚ç‚¹ï¼‰
#   7. ç›‘æ§ä»»åŠ¡æ‰§è¡Œç›´è‡³å®Œæˆ
#   8. ä¼˜é›…å…³é—­æœåŠ¡å¹¶æ¸…ç†èµ„æº
#
# å¯é…ç½®é¡¹ï¼š
#   - GPU/NPU èµ„æºé…ç½®ï¼ˆå¡æ•°ã€æ˜¾å­˜æ¯”ä¾‹ç­‰ï¼‰
#   - æ¨ç†æ‰¹å¤„ç†å‚æ•°ï¼ˆå¹¶å‘åºåˆ—æ•°ã€æ‰¹æ¬¡å¤§å°ç­‰ï¼‰
#   - ç½‘ç»œè¶…æ—¶ä¸é‡è¯•è®¾ç½®
#   - å¹¶å‘åº¦ä¸èŠ‚æµæ§åˆ¶
#   - æ—¥å¿—ä¸è¾“å‡ºè·¯å¾„
#
# ä½¿ç”¨å»ºè®®ï¼š
#   1. æ ¹æ®ç¡¬ä»¶é…ç½®è°ƒæ•´èµ„æºå‚æ•°
#   2. ç»“åˆæ•°æ®è§„æ¨¡è®¾ç½®å¹¶å‘åº¦
#   3. é…ç½®åˆé€‚çš„è¶…æ—¶ä¸é‡è¯•ç­–ç•¥
#   4. è§„åˆ’å¥½æ—¥å¿—ä¸è¾“å‡ºç®¡ç†
#
# é…ç½®å»ºè®®ï¼š
#   1. TENSOR_PARALLEL_SIZE: æ ¹æ®å®é™…æ˜¾å¡æ•°é‡è®¾ç½®
#   2. MAX_NUM_SEQS: ç»“åˆæ˜¾å­˜å¤§å°è°ƒæ•´
#   3. MAX_JOBS: ä¾æ®ç³»ç»Ÿèµ„æºè°ƒæ•´å¹¶å‘æ•°
#   4. HEALTH_TIMEOUT: æ ¹æ®ç½‘ç»œæƒ…å†µè°ƒæ•´æ£€æŸ¥è¶…æ—¶
#
# ä½¿ç”¨æ–¹æ³•ï¼š
#   ./auto_model_infer.sh [NODE_LIST_FILE]
#
# ç¯å¢ƒè¦æ±‚ï¼š
#   - bash 4.0+
#   - ssh å…å¯†é…ç½®
#   - python 3.9+
#   - vLLM
#   - CUDA/NPU é©±åŠ¨
#
# ä½œè€…ï¼šLLM Eval Team
# ç‰ˆæœ¬ï¼š3.0
# æ›´æ–°æ—¥æœŸï¼š2025
# =======================================================

# è®¾ç½®è„šæœ¬å¥å£®æ€§æ ‡å¿—ï¼š
# -e: ä»»ä½•å‘½ä»¤å¤±è´¥ç«‹å³é€€å‡º
# -u: ä½¿ç”¨æœªè®¾ç½®çš„å˜é‡è§†ä¸ºé”™è¯¯
# -o pipefail: ç®¡é“ä¸­ä»»ä½•å‘½ä»¤å¤±è´¥éƒ½é€€å‡º
set -euo pipefail

# =======================================================
#                  è°ƒè¯•æ¨¡å¼é…ç½®
# =======================================================
# å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆè®¾ç½® DEBUG=1 å¼€å¯ï¼‰
if [[ "${DEBUG:-0}" == "1" ]]; then
    set -x  # æ‰“å°æ‰§è¡Œçš„æ¯æ¡å‘½ä»¤
    # å¢å¼ºè°ƒè¯•è¾“å‡ºï¼Œæ˜¾ç¤ºæ–‡ä»¶åã€è¡Œå·å’Œå‡½æ•°å
    export PS4='+(${BASH_SOURCE}:${LINENO}): ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
    # è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
    readonly LOG_FILE="${LOG_DIR}/debug_$(date +%Y%m%d_%H%M%S).log"
fi

# =======================================================
#                  å…¨å±€å¸¸é‡ä¸é…ç½®åŒºåŸŸ
# =======================================================

# ----------------------
# SSH è¿æ¥é…ç½®
# ----------------------
# SSH ä¼˜åŒ–é€‰é¡¹é…ç½®:
# - StrictHostKeyChecking=no: å…³é—­ä¸»æœºå¯†é’¥æ£€æŸ¥ï¼Œé¿å…é¦–æ¬¡è¿æ¥è¯¢é—®
# - UserKnownHostsFile=/dev/null: ä¸è®°å½•ä¸»æœºå¯†é’¥ï¼Œå‡å°‘ç»´æŠ¤è´Ÿæ‹…
# - LogLevel=ERROR: ä»…è®°å½•é”™è¯¯æ—¥å¿—ï¼Œå‡å°‘æ—¥å¿—å™ªå£°
# - ConnectTimeout=5: è¿æ¥è¶…æ—¶è®¾ç½®ï¼Œå¿«é€Ÿå¤±è´¥
# - ServerAliveInterval=30: æ¯30ç§’å‘é€ä¿æ´»åŒ…
# - ServerAliveCountMax=3: æœ€å¤šå…è®¸3æ¬¡ä¿æ´»å¤±è´¥
# - ControlMaster=auto: å¯ç”¨è¿æ¥å¤ç”¨ï¼Œæé«˜æ€§èƒ½
# - ControlPersist=60s: ä¿æŒè¿æ¥60ç§’ï¼Œå‡å°‘é‡è¿å¼€é”€
# ä¸ºé¿å…è¡Œå†…æ³¨é‡Šç ´åå¤šè¡Œå­—ç¬¦ä¸²ï¼Œå°†æ³¨é‡Šå‰ç§»
# - BatchMode=yes: ç¦æ­¢äº¤äº’æç¤ºï¼Œä¾¿äºè‡ªåŠ¨åŒ–
readonly SSH_OPTS="-o StrictHostKeyChecking=no \
                   -o UserKnownHostsFile=/dev/null \
                   -o LogLevel=ERROR \
                   -o BatchMode=yes \
                   -o ConnectTimeout=5 \
                   -o ServerAliveInterval=30 \
                   -o ServerAliveCountMax=3 \
                   -o ControlMaster=auto \
                   -o ControlPersist=60s"

# SSH ç”¨æˆ·é…ç½®: ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå¦åˆ™ä½¿ç”¨å½“å‰ç”¨æˆ·
readonly SSH_USER="${SSH_USER:-$(whoami)}"
# =======================================================
#                  æ¨¡å‹ä¸èµ„æºé…ç½®
# =======================================================

# æ¨¡å‹è·¯å¾„é…ç½®
readonly MODEL_PATH="${MODEL_PATH:-/home/jianzhnie/llmtuner/hfhub/mindspeed/models/mindspore/hf_sft_packing_0703_step6476}"

# GPU/ASCEND èµ„æºé…ç½®
readonly TENSOR_PARALLEL_SIZE=${TENSOR_PARALLEL_SIZE:-8}    # å¼ é‡å¹¶è¡Œå¤§å°ï¼Œæ”¯æŒ TP=8
readonly INSTANCES_PER_NODE=${INSTANCES_PER_NODE:-1}        # æ¯èŠ‚ç‚¹éƒ¨ç½²å®ä¾‹æ•°ï¼ˆçµæ´»é…ç½®ï¼‰
readonly MEMORY_UTILIZATION=${MEMORY_UTILIZATION:-0.9}      # æ˜¾å­˜åˆ©ç”¨ç‡ (0.0 - 1.0)
readonly MAX_MODEL_LEN=${MAX_MODEL_LEN:-65536}              # æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
# é’ˆå¯¹ Ascend åœºæ™¯ä¸­ npu-smi è¿”å›å€¼ä¸å¯ç”¨è®¾å¤‡æ•°é‡ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œå…è®¸å¼•å…¥ä¿®æ­£å› å­
readonly DEVICE_COUNT_MULTIPLIER=${DEVICE_COUNT_MULTIPLIER:-2}

# vLLM é«˜å¹¶å‘å…³é”®å‚æ•°ï¼ˆæŒ‰éœ€è°ƒæ•´ï¼›éœ€ç»“åˆæ˜¾å­˜ä¸ä¸Šä¸‹æ–‡é•¿åº¦ï¼‰
# - MAX_NUM_SEQS: åŒæ—¶å¹¶å‘å¤„ç†çš„åºåˆ—æ•°ï¼ˆè¶Šå¤§è¶Šèƒ½ååï¼Œå—æ˜¾å­˜å½±å“è¾ƒå¤§ï¼‰
# - MAX_NUM_BATCHED_TOKENS: åŠ¨æ€æ‰¹æ¬¡å†…æ€» token ä¸Šé™ï¼ˆæ§åˆ¶æ˜¾å­˜ä¸ååæƒè¡¡ï¼‰
# æ³¨ï¼šä¸¤è€…ä¸å®œåŒæ—¶è®¾è¿‡å¤§ï¼Œæ¨èæ ¹æ®æ¨¡å‹å¤§å°æŒ‰ 1-2 æ¬¡è¯•è·‘è§‚æµ‹ GPU åˆ©ç”¨ç‡åè°ƒæ•´
readonly MAX_NUM_SEQS=${MAX_NUM_SEQS:-1024}                         # åŒæ—¶å¹¶å‘å¤„ç†çš„åºåˆ—æ•°
readonly MAX_NUM_BATCHED_TOKENS=${MAX_NUM_BATCHED_TOKENS:-32768}    # åŠ¨æ€æ‰¹æ¬¡å†…æœ€å¤§ token æ•°
readonly CPU_OFFLOAD_GB=${CPU_OFFLOAD_GB:-0}                        # CPU å¸è½½ GB å†…å­˜ï¼ˆé»˜è®¤ 0 ä¸å¯ç”¨ï¼‰
readonly SWAP_SPACE=${SWAP_SPACE:-0}                                # äº¤æ¢ç©ºé—´ GB å†…å­˜ï¼ˆé»˜è®¤ 0 ä¸å¯ç”¨ï¼‰

# Yarn é…ç½®
readonly ROPE_FACTOR=${ROPE_FACTOR:-2.0}

# å…¶ä»–æ¨ç†å‚æ•°
readonly N_SAMPLES=${N_SAMPLES:-8}                   # æ¯æ¡æ ·æœ¬çš„é‡å¤é‡‡æ ·æ¬¡æ•°
readonly SERVED_MODEL_NAME="${SERVED_MODEL_NAME:-PCL-Reasoner}"

# è®¡ç®—æ¯ä¸ªå®ä¾‹çš„è®¾å¤‡å¯è§æ€§
get_device_visibility() {
    local instance_id=$1  # 0-based
    local start_idx=$((instance_id * TENSOR_PARALLEL_SIZE))
    # Check if we have enough devices available
    local end_idx=$((start_idx + TENSOR_PARALLEL_SIZE - 1))

    # Just in case we're using ASCEND devices, we should check the actual available devices
    # This is a more robust approach than just assuming sequential device IDs
    seq -s, $start_idx $end_idx
}

get_remote_device_count() {
    local node=$1
    # ä½¿ç”¨ssh-keyscané˜²æ­¢"Host key verification failed"é”™è¯¯
    ssh-keyscan -H "$node" >/dev/null 2>&1

    # å°è¯•è¿æ¥å¹¶æ‰§è¡Œå‘½ä»¤ï¼ŒåŒæ—¶å¿½ç•¥sshè­¦å‘Š
    local output
    output=$(ssh -q -o BatchMode=yes -o ConnectTimeout=10 "$node" "npu-smi info 2>/dev/null" 2>/dev/null)

    # å¦‚æœsshå‘½ä»¤å¤±è´¥ï¼ˆä¾‹å¦‚è¿æ¥è¶…æ—¶ï¼‰ï¼Œåˆ™ç›´æ¥åˆ¤å®šä¸ºä¸å¯ç”¨
    if [ $? -ne 0 ]; then
        echo "ğŸ”´ èŠ‚ç‚¹ $node: è¿æ¥å¤±è´¥æˆ–å‘½ä»¤æ‰§è¡Œå¤±è´¥"
        echo "0"
        return 0
    fi

    # æ£€æŸ¥è¾“å‡ºä¸­æ˜¯å¦åŒ…å«"No running processes found in NPU"
    # æˆ‘ä»¬å¯ä»¥é€šè¿‡ç»Ÿè®¡"No running processes found"çš„è¡Œæ•°æ¥åˆ¤æ–­æ‰€æœ‰å¡æ˜¯å¦éƒ½ç©ºé—²
    local device_count
    device_count=$(echo "$output" | grep -c "No running processes found in NPU")

    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
    local error_lines
    error_lines=$(echo "$output" | grep -c "Error")

    if [ "$error_lines" -gt 0 ]; then
        echo "âŒ èŠ‚ç‚¹ $node: NPUå‘½ä»¤æ‰§è¡Œå‡ºé”™"
        echo "0"
        return 0
    fi

    # é€šè¿‡echoè¿”å›å®é™…çš„è®¾å¤‡æ•°é‡
    echo "$device_count"
}

# éªŒè¯èŠ‚ç‚¹çš„è®¾å¤‡æ•°é‡æ˜¯å¦æ»¡è¶³å®ä¾‹é…ç½®éœ€æ±‚
verify_node_device_capacity() {
    local node=$1

    # æ ¹æ®å‚æ•°å†³å®šNPUå¡æ•°é‡
    local required_devices=$((INSTANCES_PER_NODE * TENSOR_PARALLEL_SIZE))

    # ä»è¿œç¨‹èŠ‚ç‚¹è·å–å®é™…çš„è®¾å¤‡æ•°é‡
    local device_count_raw
    device_count_raw=$(get_remote_device_count "$node")

    # get_remote_device_count å¯èƒ½è¿”å›ç©ºæˆ–éæ•°å­—ï¼Œç»Ÿä¸€å…œåº•ä¸º 0
    if ! [[ "$device_count_raw" =~ ^[0-9]+$ ]]; then
        device_count_raw=0
    fi

    # æ ¹æ®ç¡¬ä»¶/é©±åŠ¨è¾“å‡ºæƒ…å†µåº”ç”¨ä¿®æ­£ç³»æ•°ï¼ˆAscend 910B å¸¸è§ä¸º 2ï¼‰
    local device_count=$((device_count_raw * DEVICE_COUNT_MULTIPLIER))

    # ç¡®ä¿æ‰€æœ‰NPUéƒ½ç©ºé—²
    if [[ -z "$device_count" || "$device_count" -lt "$required_devices" ]]; then
        handle_error 1 "èŠ‚ç‚¹ ${node} å¯ç”¨è®¾å¤‡æ•°é‡ (${device_count:-0}) å°‘äºè¿è¡Œ ${INSTANCES_PER_NODE} ä¸ªå®ä¾‹æ‰€éœ€çš„ ${required_devices} å¼ è®¾å¤‡ (TP=${TENSOR_PARALLEL_SIZE})"
    fi
    log_info "âœ… èŠ‚ç‚¹ ${node} å¯ç”¨è®¾å¤‡æ•° ${device_count} æ»¡è¶³ ${INSTANCES_PER_NODE} å®ä¾‹ * TP=${TENSOR_PARALLEL_SIZE} çš„éœ€æ±‚"
}

# =======================================================
#                  vLLM API Server è¿è¡Œå‚æ•°
# =======================================================

# å…³é—­è¯·æ±‚é€æ¡æ—¥å¿—ï¼Œå‡å°‘ IO æŠ–åŠ¨
readonly DISABLE_LOG_REQUESTS=${DISABLE_LOG_REQUESTS:-True}

# é¢å¤–å¼•æ“å‚æ•°ï¼ˆæŒ‰éœ€è¿½åŠ ï¼Œä¾‹å¦‚ "--dtype bfloat16 --enforce-eager"ï¼‰
readonly EXTRA_ENGINE_ARGS="${EXTRA_ENGINE_ARGS:-}"

# =======================================================
#                  è·¯å¾„é…ç½®
# =======================================================

# é¡¹ç›®è·¯å¾„é…ç½®
readonly PROJECT_DIR="${PROJECT_DIR:-/home/jianzhnie/llmtuner/llm/LLMEval}"
readonly INFER_SCRIPT="${INFER_SCRIPT:-${PROJECT_DIR}/llmeval/vllm/online_server.py}"
readonly SET_ENV_SCRIPT="${SET_ENV_SCRIPT:-${PROJECT_DIR}/set_env.sh}"

# è¾“å‡ºä¸æ—¥å¿—è·¯å¾„é…ç½®
readonly OUTPUT_ROOT="${OUTPUT_ROOT:-/home/jianzhnie/llmtuner/llm/LLMEval/output}"
readonly OUTPUT_DIR="${OUTPUT_DIR:-${OUTPUT_ROOT}/${SERVED_MODEL_NAME}}"
readonly LOG_DIR="${LOG_DIR:-${OUTPUT_ROOT}/logs-rl}"

# æ—¥å¿—æ–‡ä»¶å‰ç¼€é…ç½®
readonly API_SERVER_LOG_PREFIX="api_server_"
readonly TASK_LOG_PREFIX="task_"

# æœåŠ¡ç­‰å¾…æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰
readonly MAX_WAIT_TIME=${MAX_WAIT_TIME:-900}

# å¥åº·æ£€æŸ¥è®¾ç½®
readonly HEALTH_PATH="${HEALTH_PATH:-/health}"        # OpenAI å…¼å®¹æœåŠ¡é€šå¸¸æš´éœ² /health
readonly HEALTH_TIMEOUT=${HEALTH_TIMEOUT:-3}          # å•æ¬¡å¥åº·æ£€æŸ¥è¶…æ—¶ï¼ˆç§’ï¼‰

# =======================================================
#                  æ•°æ®é›†é…ç½®
# =======================================================

# æ•°æ®é›†è·¯å¾„é…ç½®ï¼ˆå‡å®šå„èŠ‚ç‚¹è·¯å¾„ä¸€è‡´æˆ–æŒ‚åŒä¸€ NASï¼‰
readonly DATASET_DIR="${DATASET_DIR:-${PROJECT_DIR}/data_process/model_infer}"

# æ•°æ®é›†æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆå¯è¦†ç›–ï¼‰
readonly DATASET_GLOB="${DATASET_GLOB:-top_100K_final_verified_samples_shard*}"

# =======================================================
#                  æ¨ç†å®¢æˆ·ç«¯å‚æ•°
# =======================================================
readonly INPUT_KEY="${INPUT_KEY:-question}"           # è¾“å…¥å­—æ®µé”®å
readonly SYSTEM_PROMPT_TYPE="${SYSTEM_PROMPT_TYPE:-amthinking}"
readonly MAX_WORKERS=${MAX_WORKERS:-128}               # å®¢æˆ·ç«¯æ¯è¿›ç¨‹å†…éƒ¨çš„çº¿ç¨‹/åç¨‹å¹¶å‘

# =======================================================
#                  å…¨å±€å˜é‡å£°æ˜
# =======================================================

# èŠ‚ç‚¹å’Œç«¯å£æ•°ç»„ï¼ˆåœ¨ main å‡½æ•°ä¸­åˆå§‹åŒ–ï¼‰
declare -a NODES                    # å­˜å‚¨èŠ‚ç‚¹åœ°å€
declare -a PORTS                    # å­˜å‚¨å¯¹åº”çš„æœåŠ¡ç«¯å£
declare -a FILES                    # å­˜å‚¨å‘ç°çš„æ•°æ®æ–‡ä»¶åˆ—è¡¨ï¼ˆæ–‡ä»¶åï¼‰
declare -a READY_INSTANCE_NODES     # å­˜å‚¨å·²å°±ç»ªå®ä¾‹æ‰€å±èŠ‚ç‚¹ï¼ˆæŒ‰å®ä¾‹å±•å¼€ï¼‰
declare -a READY_INSTANCE_PORTS     # å­˜å‚¨å·²å°±ç»ªå®ä¾‹ç«¯å£
declare -a READY_INSTANCE_IDS       # å­˜å‚¨å·²å°±ç»ªå®ä¾‹åœ¨èŠ‚ç‚¹å†…çš„ index

# =======================================================
#                  å·¥å…·å‡½æ•°åŒºåŸŸ
# =======================================================

# æ‰“å°ä½¿ç”¨å¸®åŠ©ä¿¡æ¯
# å‚æ•°ï¼šæ— 
# è¿”å›å€¼ï¼šæ— ï¼ˆç›´æ¥é€€å‡ºï¼‰
usage() {
    cat << EOF
ç”¨æ³•: $0 [NODE_LIST_FILE]

è·¨å¤šèŠ‚ç‚¹è‡ªåŠ¨éƒ¨ç½² vLLM å¹¶æ‰§è¡Œåˆ†å¸ƒå¼æ¨ç†ä»»åŠ¡ï¼ˆé«˜å¹¶å‘ä¼˜åŒ–ç‰ˆï¼‰ã€‚

å‚æ•°:
  NODE_LIST_FILE         èŠ‚ç‚¹åˆ—è¡¨æ–‡ä»¶ (é»˜è®¤: ./node_list_all.txt)ï¼›æ¯è¡Œä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ”¯æŒ # æ³¨é‡Šä¸ç©ºè¡Œ

å¯ç”¨ç¯å¢ƒå˜é‡ï¼ˆå¯è¦†ç›–é»˜è®¤å€¼ï¼‰:
  SSH_USER               è¿œç¨‹ SSH ç”¨æˆ·åï¼ˆé»˜è®¤ï¼šå½“å‰ç”¨æˆ·ï¼‰
  MODEL_PATH             æ¨¡å‹æ–‡ä»¶è·¯å¾„
  TENSOR_PARALLEL_SIZE   å¼ é‡å¹¶è¡Œå¡æ•°ï¼Œæ”¯æŒ {1,2,4,8}ï¼ˆé»˜è®¤ï¼š4ï¼‰
  INSTANCES_PER_NODE     æ¯èŠ‚ç‚¹å®ä¾‹æ•°ï¼ˆé»˜è®¤ï¼š2ï¼‰
  MEMORY_UTILIZATION     æ˜¾å­˜åˆ©ç”¨ç‡ï¼ˆé»˜è®¤ï¼š0.9ï¼‰
  MAX_MODEL_LEN          æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆé»˜è®¤ï¼š65536ï¼‰
  MAX_NUM_SEQS           vLLM åŠ¨æ€æ‰¹å¹¶å‘åºåˆ—æ•°ï¼ˆé»˜è®¤ï¼š1024ï¼‰
  MAX_NUM_BATCHED_TOKENS vLLM åŠ¨æ€æ‰¹ token ä¸Šé™ï¼ˆé»˜è®¤ï¼š32768ï¼‰
  N_SAMPLES              æ¯ä¸ªæ ·æœ¬é‡‡æ ·æ¬¡æ•°ï¼ˆé»˜è®¤ï¼š8ï¼‰
  SERVED_MODEL_NAME      æœåŠ¡æ¨¡å‹åç§°ï¼ˆé»˜è®¤ï¼šPCL-Reasonerï¼‰
  MAX_WAIT_TIME          æœåŠ¡å¯åŠ¨æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆé»˜è®¤ï¼š900ç§’ï¼‰
  DATASET_GLOB           æ•°æ®é›†æ–‡ä»¶åŒ¹é…æ¨¡å¼
  SYSTEM_PROMPT_TYPE     ç³»ç»Ÿæç¤ºç±»å‹ï¼ˆé»˜è®¤ï¼šamthinkingï¼‰
  MAX_WORKERS            æ¨ç†å®¢æˆ·ç«¯å†…éƒ¨å¹¶å‘ï¼ˆé»˜è®¤ï¼š32ï¼‰
  DISABLE_LOG_REQUESTS   æ˜¯å¦å…³é—­è¯·æ±‚æ—¥å¿—ï¼ˆé»˜è®¤ï¼š1ï¼‰
  EXTRA_ENGINE_ARGS      é™„åŠ å¼•æ“å‚æ•°å­—ç¬¦ä¸²ï¼ˆé»˜è®¤ï¼šç©ºï¼‰
  MAX_CONCURRENT_TASKS_PER_NODE å•èŠ‚ç‚¹æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼ˆé»˜è®¤ï¼š8ï¼‰
  DEVICE_COUNT_MULTIPLIER npu-smi ç»Ÿè®¡ä¿®æ­£å› å­ï¼ˆé»˜è®¤ï¼š2ï¼‰
  DEBUG                  å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ˆé»˜è®¤ï¼š0ï¼‰

ç¤ºä¾‹:
  $0
  SSH_USER=root TENSOR_PARALLEL_SIZE=4 MAX_NUM_SEQS=2048 $0 ./nodes.txt
  DEBUG=1 $0
EOF
    exit 1
}

# ç»Ÿä¸€çš„ SSH æ‰§è¡Œå°è£…
# Args:
#   $1: node (string) - èŠ‚ç‚¹åœ°å€
#   $@: command (string array) - è¦æ‰§è¡Œçš„å‘½ä»¤
# Returns:
#   SSH å‘½ä»¤çš„é€€å‡ºç 
ssh_run() {
    local node="$1"
    shift
    local userhost="${SSH_USER:+${SSH_USER}@}${node}"
    # ä½¿ç”¨ $@ ç¡®ä¿å‘½ä»¤ä¸­çš„ç©ºæ ¼å’Œå¼•å·è¢«æ­£ç¡®ä¼ é€’
    ssh ${SSH_OPTS} "${userhost}" "$@"
}

# é€šè¿‡ rsync åŒæ­¥æ–‡ä»¶åˆ°è¿œç¨‹èŠ‚ç‚¹
# å‚æ•°ï¼š
#   $1: æœ¬åœ°æºè·¯å¾„
#   $2: ç›®æ ‡èŠ‚ç‚¹
#   $3: è¿œç¨‹ç›®æ ‡è·¯å¾„
# è¿”å›å€¼ï¼šrsync å‘½ä»¤çš„é€€å‡ºç 
rsync_to_node() {
    local src_path="$1"
    local node="$2"
    local dst_path="$3"
    local userhost="${SSH_USER:+${SSH_USER}@}${node}"
    local RSYNC_OPTS="-avz --checksum --partial --inplace --no-whole-file --exclude='.*'"

    log_info "ğŸ”„ åŒæ­¥æ–‡ä»¶: ${src_path} -> ${userhost}:${dst_path}"

    if ! rsync ${RSYNC_OPTS} "${src_path}" "${userhost}:${dst_path}"; then
        log_error "âŒ rsync åŒæ­¥å¤±è´¥: ${src_path} -> ${userhost}:${dst_path}" >&2
        return 1
    fi

    log_info "âœ… æ–‡ä»¶åŒæ­¥å®Œæˆ: ${src_path} -> ${userhost}:${dst_path}"
}


# æ—¥å¿—å‡½æ•° (å¸¦æœ‰ Emoji æç¤º)
# Args:
#   $@: msg (string) - æ—¥å¿—æ¶ˆæ¯å†…å®¹
# Returns:
#   None (è¾“å‡ºåˆ° stdout/stderr)
log_info() {
    local msg="$*"
    local emoji="â„¹ï¸ "
    # æ ¹æ®æ¶ˆæ¯å†…å®¹é€‰æ‹©åˆé€‚çš„emoji
    case "$msg" in
        *"å¼€å§‹æ‰§è¡Œ"*|*"å¯åŠ¨"*) emoji="ğŸš€ " ;;
        *"å®Œæˆ"*|*"æˆåŠŸ"*|*"é€šè¿‡"*) emoji="âœ… " ;;
        *"å¤±è´¥"*|*"é”™è¯¯"*|*"å¼‚å¸¸"*) emoji="âŒ " ;;
        *"å‘ç°"*|*"æ£€æŸ¥"*) emoji="ğŸ” " ;;
        *"é…ç½®"*|*"è®¾ç½®"*) emoji="âš™ï¸ " ;;
        *"ç­‰å¾…"*) emoji="â³ " ;;
        *"æ¸…ç†"*) emoji="ğŸ§¹ " ;;
        *"åˆ†é…"*|*"éƒ¨ç½²"*) emoji="ğŸ“¦ " ;;
        *"èŠ‚ç‚¹"*|*"æœåŠ¡"*) emoji="ğŸ’» " ;;
        *"ç«¯å£"*) emoji="ğŸ”Œ " ;;
        *"æ–‡ä»¶"*) emoji="ğŸ“„ " ;;
        *"ç»Ÿè®¡"*) emoji="ğŸ“Š " ;;
    esac
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] INFO: ${emoji}$msg"
}

log_warn() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] WARN: âš ï¸ $*" >&2
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: âŒ $*" >&2
}

# é”™è¯¯å¤„ç†å‡½æ•°ï¼Œå¹¶åœ¨é€€å‡ºå‰æ¸…ç†èµ„æº
# Args:
#   $1: exit_code (int) - é€€å‡ºç 
#   $2: error_msg (string) - é”™è¯¯æ¶ˆæ¯
# Returns:
#   None (ç›´æ¥é€€å‡ºè„šæœ¬)
handle_error() {
    local exit_code=$1
    local error_msg=$2
    log_error "$error_msg"

    # è°ƒç”¨æ¸…ç†å‡½æ•°
    cleanup_and_exit "$exit_code"
}

# æ–‡ä»¶é”ç®¡ç† (ä½¿ç”¨ PID)
LOCK_FILE="$LOG_DIR/vllm_deploy.lock"

acquire_lock() {
    if [ -e "$LOCK_FILE" ]; then
        local pid
        pid=$(cat "$LOCK_FILE")
        # æ£€æŸ¥ PID æ˜¯å¦ä»åœ¨è¿è¡Œ
        if kill -0 "$pid" 2>/dev/null; then
            handle_error 1 "å¦ä¸€ä¸ªéƒ¨ç½²è¿›ç¨‹ (PID: $pid) æ­£åœ¨è¿è¡Œ"
        fi
        # å¦‚æœ PID ä¸å­˜åœ¨ï¼Œåˆ é™¤æ—§é”
        rm -f "$LOCK_FILE"
    fi
    echo $$ > "$LOCK_FILE"
}

release_lock() {
    rm -f "$LOCK_FILE"
}

# æƒé™æ£€æŸ¥å‡½æ•°
# Args:
#   $1: dir (string) - ç›®å½•è·¯å¾„
# Returns:
#   0: æˆåŠŸï¼Œ1: å¤±è´¥ (é€šè¿‡ handle_error é€€å‡º)
check_permissions() {
    local dir="$1"
    if [[ ! -w "$dir" ]]; then
        handle_error 1 "æœ¬åœ°ç›®å½• $dir æ²¡æœ‰å†™å…¥æƒé™"
    fi
}

# èŠ‚ç‚¹è¿é€šæ€§æ£€æŸ¥
# Args:
#   $1: node (string) - èŠ‚ç‚¹åœ°å€
# Returns:
#   0: æˆåŠŸï¼Œ1: å¤±è´¥
validate_node() {
    local node="$1"
    # ä½¿ç”¨ -q (quiet) é¿å…è¾“å‡ºï¼Œé€šè¿‡é€€å‡ºç åˆ¤æ–­è¿é€šæ€§
    if ssh -q "${SSH_USER:+${SSH_USER}@}${node}" exit 2>/dev/null; then
        log_info "âœ… èŠ‚ç‚¹ ${node} è¿é€šæ€§æ£€æŸ¥é€šè¿‡"
        return 0
    else
        log_warn "âš ï¸ æ— æ³•è¿æ¥åˆ°èŠ‚ç‚¹ $node"
        return 1
    fi
}

# æ£€æŸ¥èŠ‚ç‚¹ä¸Šçš„ PROJECT_DIR å’Œ DATASET_DIR æ˜¯å¦å­˜åœ¨
# Args:
#   $1: node (string) - èŠ‚ç‚¹åœ°å€
# Returns:
#   0: æˆåŠŸï¼Œ1: å¤±è´¥
validate_node_directories() {
    local node="$1"

    log_info "ğŸ” æ£€æŸ¥èŠ‚ç‚¹ ${node} ä¸Šçš„å¿…è¦ç›®å½•æ˜¯å¦å­˜åœ¨"

    # æ£€æŸ¥ PROJECT_DIR æ˜¯å¦å­˜åœ¨
    if ! ssh_run "$node" "[[ -d '${PROJECT_DIR}' ]]"; then
        log_error "âŒ èŠ‚ç‚¹ ${node} ä¸Š PROJECT_DIR ä¸å­˜åœ¨: ${PROJECT_DIR}"
        return 1
    fi

    # æ£€æŸ¥ DATASET_DIR æ˜¯å¦å­˜åœ¨
    if ! ssh_run "$node" "[[ -d '${DATASET_DIR}' ]]"; then
        log_error "âŒ èŠ‚ç‚¹ ${node} ä¸Š DATASET_DIR ä¸å­˜åœ¨: ${DATASET_DIR}"
        return 1
    fi

    log_info "âœ… èŠ‚ç‚¹ ${node} ä¸Šçš„ PROJECT_DIR å’Œ DATASET_DIR æ£€æŸ¥é€šè¿‡"
    return 0
}


# ä¼˜é›…æ¸…ç†æ‰€æœ‰èµ„æºå¹¶é€€å‡º
# Args:
#   $1: exit_code (int, optional) - é€€å‡ºç ï¼Œé»˜è®¤ä¸ºæœ€åä¸€æ¬¡å‘½ä»¤çš„é€€å‡ºç 
# Returns:
#   None (é€€å‡ºè„šæœ¬)
cleanup_and_exit() {
    # å¦‚æœæ²¡æœ‰ä¼ é€’é€€å‡ºç ï¼Œä½¿ç”¨ä¸Šä¸€ä¸ªå‘½ä»¤çš„é€€å‡ºç 
    local exit_code="${1:-$?}"

    log_info "å¼€å§‹æ¸…ç†èµ„æº..."

    # åœæ­¢æ‰€æœ‰æœåŠ¡
    stop_services

    # é‡Šæ”¾æ–‡ä»¶é”
    release_lock

    # å¦‚æœæ˜¯è°ƒè¯•æ¨¡å¼ï¼Œå…³é—­å®ƒ
    [[ "${DEBUG:-0}" == "1" ]] && set +x

    log_info "æ¸…ç†å®Œæˆï¼Œé€€å‡ºä»£ç : $exit_code"
    exit "$exit_code"
}


# éªŒè¯é…ç½®å‚æ•°
# Args:
#   None
# Returns:
#   None (éªŒè¯å¤±è´¥æ—¶é€šè¿‡ handle_error é€€å‡º)
validate_config() {
    log_info "å¼€å§‹éªŒè¯é…ç½®å‚æ•°..."

    # éªŒè¯å¿…è¦æ–‡ä»¶å­˜åœ¨æ€§
    local required_files=(
        "$INFER_SCRIPT"
        "$SET_ENV_SCRIPT"
    )

    for file in "${required_files[@]}"; do
        if [[ ! -f "$file" ]]; then
            handle_error 1 "å¿…éœ€æ–‡ä»¶ä¸å­˜åœ¨: $file"
        fi
        if [[ ! -r "$file" ]]; then
            handle_error 1 "æ–‡ä»¶æ²¡æœ‰è¯»å–æƒé™: $file"
        fi
    done

    # éªŒè¯æœ¬åœ°ç›®å½•æƒé™
    local required_dirs=(
        "$OUTPUT_DIR"
        "$LOG_DIR"
        "$DATASET_DIR"
    )

    # æå‰åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œç¡®ä¿æƒé™æ£€æŸ¥é€šè¿‡
    mkdir -p "${OUTPUT_DIR}" "${LOG_DIR}" || true

    for dir in "${required_dirs[@]}"; do
        check_permissions "$dir"
    done

    # éªŒè¯æ•°å€¼å‚æ•°èŒƒå›´
    # å‚æ•°å: æœ€å°å€¼: æœ€å¤§å€¼: æè¿°
    local param_checks=(
        "TENSOR_PARALLEL_SIZE:1:8:GPUæ•°é‡"
        "INSTANCES_PER_NODE:1:4:æ¯èŠ‚ç‚¹å®ä¾‹æ•°"
        "N_SAMPLES:1:100:é‡‡æ ·æ¬¡æ•°"
        "MAX_NUM_SEQS:1:16384:å¹¶å‘åºåˆ—æ•°"
        "MAX_NUM_BATCHED_TOKENS:512:1048576:æ‰¹å¤„ç†Tokenæ•°"
    )

    for check in "${param_checks[@]}"; do
        # Bash æŠ€å·§: ä½¿ç”¨ IFS æ‹†åˆ†å­—ç¬¦ä¸²
        IFS=':' read -r param min max desc <<< "$check"
        local value
        # Bash æŠ€å·§: ä½¿ç”¨ eval è·å–å˜é‡å€¼ (ä»…é™é…ç½®åŒºï¼Œé£é™©å¯æ§)
        value=$(eval echo "\$$param")
        # Bash æŠ€å·§: ä½¿ç”¨ [[ ... ]] å’Œç®—æœ¯æ‰©å±•è¿›è¡Œæ•°å€¼æ¯”è¾ƒ
        if [[ $value -lt $min || $value -gt $max ]]; then
            handle_error 1 "$desc ($param) éœ€åœ¨ $min-$max ä¹‹é—´ï¼Œå½“å‰å€¼: $value"
        fi
    done

    # éªŒè¯æµ®ç‚¹æ•°å‚æ•° (ä½¿ç”¨ bc è¿›è¡Œæµ®ç‚¹æ¯”è¾ƒ)
    if [[ $(echo "${MEMORY_UTILIZATION} < 0.1 || ${MEMORY_UTILIZATION} > 1.0" | bc -l) -eq 1 ]]; then
        handle_error 1 "æ˜¾å­˜åˆ©ç”¨ç‡éœ€åœ¨ 0.1-1.0 ä¹‹é—´ï¼Œå½“å‰å€¼: ${MEMORY_UTILIZATION}"
    fi

    log_info "âœ… é…ç½®å‚æ•°éªŒè¯é€šè¿‡"
}

# =======================================================
#                  æ ¸å¿ƒåŠŸèƒ½å‡½æ•°åŒºåŸŸ
# =======================================================

# åœæ­¢æŒ‡å®šèŠ‚ç‚¹ä¸Šçš„ vLLM æœåŠ¡
# Args:
#   $1: node (string) - èŠ‚ç‚¹åœ°å€
#   $2: port (int, optional) - æœåŠ¡ç«¯å£ï¼ˆå¯é€‰ï¼Œç”¨äºç²¾ç¡®åœæ­¢ç‰¹å®šç«¯å£çš„æœåŠ¡ï¼‰
# Returns:
#   0: æˆåŠŸï¼Œ1: å¤±è´¥
stop_service_on_node() {
    local node="$1"
    local port="${2:-}"
    local search_pattern="vllm.entrypoints.openai.api_server"

    log_info "ğŸ›‘ æ­£åœ¨åœæ­¢èŠ‚ç‚¹ ${node} ä¸Šçš„ vLLM æœåŠ¡..."

    # å¦‚æœæŒ‡å®šäº†ç«¯å£ï¼Œåˆ™ç²¾ç¡®åœæ­¢è¯¥ç«¯å£çš„æœåŠ¡
    if [[ -n "$port" ]]; then
        search_pattern="vllm.entrypoints.openai.api_server.*--port ${port}"
    fi

    # ä¼˜é›…å…³é—­ï¼šå…ˆå‘é€ SIGTERM
    if ! ssh_run "$node" "pkill -f '${search_pattern}' || true"; then
        log_error "âŒ èŠ‚ç‚¹ ${node} ä¸Šçš„ vLLM è¿›ç¨‹åœæ­¢å‘½ä»¤å‘é€å¤±è´¥"
        return 1
    fi

    # ç­‰å¾…è¿›ç¨‹ä¼˜é›…é€€å‡º
    sleep 2

    # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å·²åœæ­¢
    local remaining
    remaining=$(ssh_run "$node" "pgrep -f '${search_pattern}' | wc -l" 2>/dev/null || echo "0")

    if [[ "${remaining:-0}" -gt 0 ]]; then
        log_warn "âš ï¸ èŠ‚ç‚¹ ${node} ä¸Šä»æœ‰ ${remaining} ä¸ª vLLM è¿›ç¨‹ï¼Œå°è¯•å¼ºåˆ¶ç»ˆæ­¢..."
        ssh_run "$node" "pkill -9 -f '${search_pattern}' || true"
        sleep 1
    fi

    log_info "âœ… èŠ‚ç‚¹ ${node} ä¸Šçš„ vLLM æœåŠ¡å·²åœæ­¢"
    return 0
}



# åœæ­¢æ‰€æœ‰è¿œç¨‹èŠ‚ç‚¹ä¸Šçš„æ¨¡å‹æœåŠ¡
# Args:
#   None
# Returns:
#   None
stop_services() {
    log_info "ğŸ›‘ è„šæœ¬é€€å‡ºï¼Œæ­£åœ¨åœæ­¢æ‰€æœ‰è¿œç¨‹æ¨¡å‹æœåŠ¡..."

    local search_pattern="vllm.entrypoints.openai.api_server"
    local pids=()

    # éå†å½“å‰å·²çŸ¥çš„èŠ‚ç‚¹åˆ—è¡¨ (å¯èƒ½å·²è¢« main å‡½æ•°æ›´æ–°ä¸º available_nodes)
    for node in "${NODES[@]}"; do
        log_info "æ­£åœ¨åœæ­¢èŠ‚ç‚¹ ${node} ä¸Šçš„ vLLM è¿›ç¨‹..."
        (
            # ä½¿ç”¨ pkill ä¼˜é›…åœ°å‘é€ SIGTERMï¼Œå¹¶å¿½ç•¥é”™è¯¯ï¼ˆå¦‚æœè¿›ç¨‹å·²åœæ­¢ï¼‰
            ssh_run "$node" "pkill -f '${search_pattern}' || true"
            # ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿è¿›ç¨‹å®Œå…¨åœæ­¢
            sleep 3
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç›¸å…³è¿›ç¨‹åœ¨è¿è¡Œ
            local remaining_processes
            remaining_processes=$(ssh_run "$node" "pgrep -f '${search_pattern}' | wc -l" 2>/dev/null || echo "0")
            if [[ "${remaining_processes:-0}" -gt 0 ]]; then
                log_warn "èŠ‚ç‚¹ ${node} ä¸Šä»æœ‰ ${remaining_processes} ä¸ª vLLM è¿›ç¨‹åœ¨è¿è¡Œï¼Œå°è¯•å¼ºåˆ¶ç»ˆæ­¢..."
                ssh_run "$node" "pkill -9 -f '${search_pattern}' || true"
            fi
            log_info "âœ… èŠ‚ç‚¹ ${node} æœåŠ¡å·²åœæ­¢"
        ) &
        pids+=($!)
    done

    # ç­‰å¾…æ‰€æœ‰åœæ­¢æ“ä½œå®Œæˆ
    if [[ ${#pids[@]} -gt 0 ]]; then
        log_info "â³ ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹æœåŠ¡åœæ­¢..."
        wait "${pids[@]}" || true
    fi
    log_info "âœ… æ‰€æœ‰è¿œç¨‹æ¨¡å‹æœåŠ¡åœæ­¢å®Œæˆ"
}

# ç«¯å£æ¢æ´»ï¼ˆè¿œç¨‹æ˜¯å¦å¯ç”¨ï¼‰
# Args:
#   $1: node (string) - èŠ‚ç‚¹åœ°å€
#   $2: port (int) - æœåŠ¡ç«¯å£
# Returns:
#   None (å¦‚æœç«¯å£è¢«å ç”¨ï¼Œå°è¯•æ¸…ç†)
check_remote_port_free() {
    local node="$1"
    local port="$2"
    local used=0

    # å°è¯•é€šè¿‡ ss, netstat æˆ– lsof æ£€æŸ¥ç«¯å£å ç”¨æƒ…å†µ
    # æ³¨æ„ï¼šè¿™äº›å‘½ä»¤åœ¨ä¸åŒç³»ç»Ÿä¸Šå¯èƒ½ä¸åŒï¼Œå°è¯•å¤šä¸ªä»¥æé«˜å…¼å®¹æ€§
    used=$(ssh_run "$node" "ss -ltn '( sport = :$port )' 2>/dev/null | tail -n +2 | wc -l" 2>/dev/null || echo 0)
    if [[ "${used:-0}" -eq 0 ]]; then
        used=$(ssh_run "$node" "netstat -ltn 2>/dev/null | awk '{print \$4}' | grep -E '[:.]${port}\$' | wc -l" 2>/dev/null || echo 0)
    fi
    if [[ "${used:-0}" -eq 0 ]]; then
        used=$(ssh_run "$node" "lsof -iTCP:${port} -sTCP:LISTEN -nP 2>/dev/null | wc -l" 2>/dev/null || echo 0)
    fi
    if [[ "${used:-0}" -gt 0 ]]; then
        log_warn "èŠ‚ç‚¹ ${node} ç«¯å£ ${port} å·²è¢«å ç”¨ï¼Œå°è¯•æ¸…ç†æ—§ vLLM è¿›ç¨‹..."
        # å°è¯•é€šè¿‡åŒ¹é…ç«¯å£çš„ vLLM è¿›ç¨‹æ€æ‰æ—§æœåŠ¡
        ssh_run "$node" "pkill -f 'vllm.entrypoints.openai.api_server.*--port ${port}' || true" >/dev/null 2>&1 || true
        sleep 1
    fi
}


# æ£€æŸ¥èŠ‚ç‚¹ä¸ç«¯å£åˆ—è¡¨æ•°é‡æ˜¯å¦ä¸€è‡´
# å‚æ•°ï¼šæ— 
# è¿”å›å€¼ï¼šæ— ï¼ˆæ£€æŸ¥å¤±è´¥æ—¶é€€å‡ºï¼‰
check_node_port_alignment() {
    if [[ ${#NODES[@]} -ne ${#PORTS[@]} ]]; then
        log_error "èŠ‚ç‚¹æ•°é‡ (${#NODES[@]}) ä¸ç«¯å£æ•°é‡ (${#PORTS[@]}) ä¸ä¸€è‡´"
        exit 1
    fi
    log_info "èŠ‚ç‚¹å’Œç«¯å£é…ç½®æ£€æŸ¥é€šè¿‡"
}

# åœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä¸Šå‘ç°æ•°æ®é›†æ–‡ä»¶
# Args:
#   None
# Returns:
#   None (æ–‡ä»¶åˆ—è¡¨å­˜å‚¨åˆ°å…¨å±€ FILES æ•°ç»„)
discover_remote_dataset_files() {
    if [[ ${#NODES[@]} -eq 0 ]]; then
        log_error "é”™è¯¯: æ— å¯ç”¨èŠ‚ç‚¹è¿›è¡Œæ•°æ®æ–‡ä»¶å‘ç°"
        exit 1
    fi

    local head_node="${NODES[0]}"
    local search_path="${DATASET_DIR}/${DATASET_GLOB}"
    log_info "ğŸ” æ­£åœ¨èŠ‚ç‚¹ ${head_node} ä¸Šå‘ç°æ•°æ®æ–‡ä»¶: ${search_path}"

    # Bash æŠ€å·§: ä½¿ç”¨ xargs -n1 basename | sort -V å®ç°æŒ‰è‡ªç„¶æ•°å€¼æ’åºçš„æ–‡ä»¶ååˆ—è¡¨
    # ä¿®å¤: ä½¿ç”¨ -type f ç¡®ä¿åªæŸ¥æ‰¾æ–‡ä»¶ï¼Œä¸åŒ…æ‹¬ç›®å½•
    local find_cmd="sh -lc 'find ${DATASET_DIR} -maxdepth 1 -name \"${DATASET_GLOB}\" -type f 2>/dev/null | xargs -n1 basename | LC_ALL=C sort -V'"

    local out
    if ! out=$(ssh_run "$head_node" "$find_cmd"); then
        log_error "âŒ æ— æ³•åœ¨èŠ‚ç‚¹ ${head_node} ä¸Šåˆ—å‡ºæ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ä¸æƒé™"
        exit 1
    fi

    # å°†ç»“æœå­˜å‚¨åˆ°å…¨å±€æ•°ç»„ FILES
    # Bash æŠ€å·§: mapfile -t < <(...) é¿å…åˆ›å»º subshell å¯¼è‡´å˜é‡æ— æ³•ä¿®æ”¹
    mapfile -t FILES < <(printf "%s\n" "$out" || true)

    if [[ ${#FILES[@]} -eq 0 ]]; then
        log_error "âŒ æœªå‘ç°ä»»ä½•åŒ¹é…çš„æ•°æ®æ–‡ä»¶ (æ¨¡å¼: ${DATASET_GLOB})ï¼Œè¯·æ£€æŸ¥ ${DATASET_DIR} å’Œ ${DATASET_GLOB} é…ç½®"
        exit 1
    fi

    log_info "âœ… å‘ç°æ•°æ®é›†æ–‡ä»¶æ•°é‡: ${#FILES[@]}"
    # ä»…è¾“å‡ºå‰5ä¸ªæ–‡ä»¶ç¤ºä¾‹
    log_info "æ–‡ä»¶åˆ—è¡¨ (å‰5ä¸ª): ${FILES[*]:0:5}..."
}

# æ£€æŸ¥å¹¶åˆ›å»ºè¿œç¨‹ç›®å½•ï¼Œæ¸…ç†æ—§æ—¥å¿—
# Args:
#   None
# Returns:
#   None
check_and_prepare_remote_dirs() {
    log_info "âš™ï¸ æ­£åœ¨æ£€æŸ¥å¹¶åˆ›å»ºè¿œç¨‹ç›®å½•ï¼Œæ¸…ç†æ—§æ—¥å¿—..."

    for node in "${NODES[@]}"; do
        log_info "å¤„ç†èŠ‚ç‚¹: ${node}"

        # é¦–å…ˆéªŒè¯èŠ‚ç‚¹ä¸Šçš„ PROJECT_DIR å’Œ DATASET_DIR æ˜¯å¦å­˜åœ¨
        if ! validate_node_directories "$node"; then
            exit 1
        fi

        # ç¡®ä¿å•èŠ‚ç‚¹èµ„æºæ»¡è¶³ INSTANCES_PER_NODE * TENSOR_PARALLEL_SIZE çš„éƒ¨ç½²è¦æ±‚
        verify_node_device_capacity "$node"

        # åˆ›å»ºç›®å½•ï¼Œæ¸…ç†æ—§çš„çŠ¶æ€/æ—¥å¿—æ–‡ä»¶
        local prep_cmd="mkdir -p '${OUTPUT_DIR}' '${DATASET_DIR}' '${LOG_DIR}' && \
            rm -rf '${LOG_DIR}/status' && mkdir -p '${LOG_DIR}/status' && \
            rm -f '${LOG_DIR}/${API_SERVER_LOG_PREFIX}'*.log '${LOG_DIR}/${TASK_LOG_PREFIX}'*.log 2>/dev/null || true"

        if ! ssh_run "$node" "$prep_cmd"; then
            log_error "âŒ æ— æ³•åœ¨èŠ‚ç‚¹ ${node} ä¸Šå‡†å¤‡ç›®å½•ï¼Œè¯·æ£€æŸ¥SSHè¿æ¥å’Œæƒé™"
            exit 1 # åœ¨ subshell ä¸­é€€å‡º
        fi
    done

    log_info "âœ… æ‰€æœ‰è¿œç¨‹ç›®å½•å·²å°±ç»ªï¼Œæ—§æ—¥å¿—å·²æ¸…ç†"
}

# åœ¨æŒ‡å®šèŠ‚ç‚¹éƒ¨ç½² vLLM æ¨¡å‹æœåŠ¡
# åŠŸèƒ½: åœ¨è¿œç¨‹èŠ‚ç‚¹ä¸Šå¯åŠ¨ vLLM æ¨¡å‹æœåŠ¡å®ä¾‹
# å‚æ•°:
#   $1: èŠ‚ç‚¹åœ°å€ - è¿œç¨‹æœåŠ¡å™¨çš„åŸŸåæˆ–IP
#   $2: æœåŠ¡ç«¯å£ - æœåŠ¡ç›‘å¬çš„ç«¯å£å·
#   $3: å®ä¾‹ID - å®ä¾‹ç¼–å· (0-based)
# è¿”å›å€¼:
#   0: éƒ¨ç½²å‘½ä»¤å‘é€æˆåŠŸ
#   1: èŠ‚ç‚¹éªŒè¯æˆ–å‘½ä»¤å‘é€å¤±è´¥
# æ³¨æ„äº‹é¡¹:
#   - ä¼šè‡ªåŠ¨æ¸…ç†å·²å ç”¨ç«¯å£çš„æ—§è¿›ç¨‹
#   - æœåŠ¡å¯åŠ¨ä¸ºå¼‚æ­¥æ“ä½œï¼Œéœ€è¦åç»­å¥åº·æ£€æŸ¥ç¡®è®¤
#   - æ—¥å¿—ä¼šé‡å®šå‘åˆ°æŒ‡å®šæ–‡ä»¶
#   - ä½¿ç”¨ nohup ç¡®ä¿æœåŠ¡åœ¨ SSH æ–­å¼€åç»§ç»­è¿è¡Œ
deploy_model_service() {
    local node="$1"
    local port="$2"
    local instance_id="$3"
    local devices=$(get_device_visibility "$instance_id")
    local log_file="${LOG_DIR}/${API_SERVER_LOG_PREFIX}${node//./_}.log"
    local expanded_max_len rope_scaling vllm_cmd

    log_info "ğŸš€ æ­£åœ¨èŠ‚ç‚¹ ${node} ä¸Šéƒ¨ç½²æ¨¡å‹æœåŠ¡ (ç«¯å£: ${port}, TP: ${TENSOR_PARALLEL_SIZE}, å†…å­˜: ${MEMORY_UTILIZATION})"

    # 1. èŠ‚ç‚¹è¿é€šæ€§éªŒè¯
    if ! validate_node "$node"; then
        return 1
    fi

    # 2. æ£€æŸ¥å¹¶æ¸…ç†æ—§ç«¯å£å ç”¨
    log_info "ğŸ” æ£€æŸ¥èŠ‚ç‚¹ ${node} ç«¯å£ ${port} å ç”¨æƒ…å†µ"
    check_remote_port_free "$node" "$port"

    # 3. æ„å»º vLLM å¯åŠ¨å‘½ä»¤
    # å…³é”®å‚æ•°ï¼š
    #   --max-num-seqs              å¹¶å‘åºåˆ—æ•°ä¸Šé™
    #   --max-num-batched-tokens    åŠ¨æ€æ‰¹å†… token ä¸Šé™
    #   --disable-log-requests      å…³é—­è¯·æ±‚æ—¥å¿—ï¼ˆå‡å° I/Oï¼‰
    #   --tensor-parallel-size      ä½¿ç”¨å¤šå¡å¹¶è¡Œ
    #   --gpu-memory-utilization    æ§åˆ¶æ˜¾å­˜æ°´ä½ï¼ˆé¿å… OOMï¼‰
    #   --max-model-len             æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
    #   --cpu-offload-gb            å¯ç”¨ CPU å¸è½½ï¼ˆGB å†…å­˜ï¼‰
    #   --enforce-eager             å¼ºåˆ¶ä½¿ç”¨ eager æ¨¡å¼
    #   --dtype                     æ¨¡å‹ç²¾åº¦
    # æç¤ºï¼šå¦‚éœ€å¼€å¯æ··åˆç²¾åº¦/å¼ºåˆ¶ eagerï¼Œå¯åœ¨ EXTRA_ENGINE_ARGS ä¸­è¿½åŠ 

    rope_scaling="{\"rope_type\":\"yarn\",\"factor\":${ROPE_FACTOR},\"original_max_position_embeddings\":${MAX_MODEL_LEN}}"

    # è®¡ç®—æ‰©å±•åçš„æœ€å¤§æ¨¡å‹é•¿åº¦
    expanded_max_len=$(awk "BEGIN {print int((${MAX_MODEL_LEN}) * (${ROPE_FACTOR}))}")

    if [[ $expanded_max_len -lt $MAX_MODEL_LEN ]]; then
        log_error "âŒ è®¡ç®—é”™è¯¯: æ‰©å±•é•¿åº¦(${expanded_max_len})å°äºåŸå§‹é•¿åº¦(${MAX_MODEL_LEN})"
        return 1
    fi

    # æ„å»º vLLM å¯åŠ¨å‘½ä»¤ï¼ˆå•è¡Œå‘½ä»¤ï¼Œé¿å…è½¬ä¹‰é—®é¢˜ï¼‰
    local vllm_cmd="cd '${PROJECT_DIR}' && \
        source '${SET_ENV_SCRIPT}' && \
        export ASCEND_RT_VISIBLE_DEVICES='${devices}' && \
        nohup python -m vllm.entrypoints.openai.api_server \
            --model '${MODEL_PATH}' \
            --trust-remote-code \
            --enforce-eager \
            --served-model-name '${SERVED_MODEL_NAME}' \
            --tensor-parallel-size ${TENSOR_PARALLEL_SIZE} \
            --gpu-memory-utilization ${MEMORY_UTILIZATION} \
            --rope-scaling '${rope_scaling}' \
            --max-model-len ${expanded_max_len} \
            --max_num_batched_tokens ${MAX_NUM_BATCHED_TOKENS} \
            --cpu-offload-gb ${CPU_OFFLOAD_GB} \
            --max-num-seqs ${MAX_NUM_SEQS} \
            --enable-chunked-prefill \
            --swap-space ${SWAP_SPACE} \
            --port ${port} \
            --dtype float16 \
            > '${log_file}' 2>&1 &"

    log_info "æ„å»ºçš„vLLMå‘½ä»¤:\n${vllm_cmd//\\/\\\\}"

    # 4. åœ¨åå°å¯åŠ¨æœåŠ¡
    log_info "ğŸ”„ æ‰§è¡Œéƒ¨ç½²å‘½ä»¤åˆ°èŠ‚ç‚¹: ${node}, å®ä¾‹: ${instance_id}, ç«¯å£: ${port}"
    ssh_run "$node" "$vllm_cmd" &
    log_info "âœ… èŠ‚ç‚¹ ${node} vLLM æ¨¡å‹éƒ¨ç½²å‘½ä»¤å‘é€æˆåŠŸ"
}

# å¥åº·æ£€æŸ¥ï¼ˆHTTP æ¢æ´» + æ—¥å¿—å›é€€ï¼‰
# Args:
#   $1: node (string) - èŠ‚ç‚¹åœ°å€
#   $2: port (int) - æœåŠ¡ç«¯å£
# Returns:
#   0: å¥åº·æ£€æŸ¥é€šè¿‡ï¼Œ1: æ£€æŸ¥å¤±è´¥
check_service_ready() {
    local node="$1"
    local port="$2"
    local log_file="${LOG_DIR}/${API_SERVER_LOG_PREFIX}${node//./_}.log"
    local base_url="http://127.0.0.1:${port}"
    local http_status models_status

    log_info "ğŸ” æ£€æŸ¥èŠ‚ç‚¹ ${node}  (ç«¯å£: ${port}) ä¸Š vllm æ¨¡å‹éƒ¨ç½²çŠ¶æ€"
    # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if ! ssh_run "$node" "[[ -f '${log_file}' ]]"; then
        log_warn "âš ï¸ èŠ‚ç‚¹ ${node} çš„æ—¥å¿—æ–‡ä»¶å°šæœªåˆ›å»º: ${log_file}"
        return 1
    fi

    # 1. æ£€æŸ¥æœåŠ¡è¿›ç¨‹æ˜¯å¦å­˜åœ¨
    if ! ssh_run "$node" "pgrep -f 'vllm.entrypoints.openai.api_server.*--port ${port}' > /dev/null"; then
        log_warn "âš ï¸ èŠ‚ç‚¹ ${node} ä¸Šçš„æœåŠ¡è¿›ç¨‹æœªè¿è¡Œæˆ–å·²é€€å‡º"
        return 1
    fi

    # 2. å°è¯• HTTP å¥åº·æ£€æŸ¥ (/health)
    http_status=$(ssh_run "$node" "curl -s -o /dev/null -w '%{http_code}' --max-time ${HEALTH_TIMEOUT} \
        ${base_url}${HEALTH_PATH} 2>/dev/null || echo 0")

    if [[ $http_status -eq 200 ]]; then
        log_info "âœ… æœåŠ¡ ${node}:${port} å¥åº·æ£€æŸ¥ (${HEALTH_PATH}) é€šè¿‡"
        return 0
    fi

    # 3. å…¼å®¹æ€§æ£€æŸ¥ï¼šå°è¯• /v1/models (vLLM OpenAI å…¼å®¹å±‚æ ‡å‡†)
    models_status=$(ssh_run "$node" "curl -s -o /dev/null -w '%{http_code}' --max-time ${HEALTH_TIMEOUT} \
        ${base_url}/v1/models 2>/dev/null || echo 0")

    if [[ $models_status -eq 200 ]]; then
        log_info "âœ… æœåŠ¡ ${node}:${port} /v1/models æ¥å£æ£€æŸ¥é€šè¿‡"
        return 0
    fi

    # 4. æ—¥å¿—å›é€€æ£€æŸ¥ï¼šæŸ¥æ‰¾å¯åŠ¨å®Œæˆæ ‡å¿—
    if ssh_run "$node" "grep -q 'Application startup complete' '${log_file}' 2>/dev/null"; then
        log_info "âœ… æœåŠ¡ ${node}:${port} æ—¥å¿—æ£€æµ‹åˆ° [Application startup complete] æ ‡å¿—, vllm å¯åŠ¨å®Œæˆ"
        return 0
    fi
    log_warn "âš ï¸ èŠ‚ç‚¹ ${node} çš„ vllm æœåŠ¡å¯åŠ¨æœªå®Œæˆ (HTTPçŠ¶æ€ç : ${http_status}/${models_status})ï¼Œæ—¥å¿—ä¸­æœªæ‰¾åˆ°å¯åŠ¨å®Œæˆæ ‡å¿—"
    return 1
}

# è½®è¯¢æ£€æŸ¥æ‰€æœ‰æ¨¡å‹æœåŠ¡æ˜¯å¦å¯åŠ¨æˆåŠŸ
# Args:
#   None
# Returns:
#   None (ä¸è¿”å›ä»»ä½•å€¼ï¼Œæ”¹ä¸ºåœ¨å‡½æ•°å¤–éƒ¨æ£€æŸ¥çŠ¶æ€æ–‡ä»¶)
wait_for_services() {
    log_info "â³ æ­£åœ¨ç­‰å¾…æ‰€æœ‰æ¨¡å‹æœåŠ¡å¯åŠ¨å¹¶å°±ç»ª... æœ€é•¿ç­‰å¾… ${MAX_WAIT_TIME} ç§’"

    local total_wait_time=0
    local interval=10
    local total_services=${#NODES[@]}
    local status_dir="${LOG_DIR}/status"

    # ç¡®ä¿çŠ¶æ€ç›®å½•å¹²å‡€
    rm -rf "${status_dir}" || true
    mkdir -p "${status_dir}"

    while [[ $total_wait_time -lt $MAX_WAIT_TIME ]]; do
        local running_pids=()

        # å¹¶è¡Œæ£€æŸ¥æ‰€æœ‰æœåŠ¡çŠ¶æ€
        for ((i = 0; i < total_services; i++)); do
            local node="${NODES[i]}"
            local port="${PORTS[i]}"
            local status_file="${status_dir}/status_${node//./_}.ok"

            # è·³è¿‡å·²å°±ç»ªçš„æœåŠ¡
            if [[ -f "$status_file" ]]; then
                continue
            fi

            # åå°æ£€æŸ¥æœåŠ¡çŠ¶æ€
            (
                if check_service_ready "$node" "$port"; then
                    touch "$status_file"
                fi
            ) &
            running_pids+=($!)
        done

        # ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹çš„æ£€æŸ¥å®Œæˆ
        if [[ ${#running_pids[@]} -gt 0 ]]; then
            wait "${running_pids[@]}" || true
        fi

        # ç»Ÿè®¡å·²å°±ç»ªæœåŠ¡æ•°é‡
        local ready_count
        ready_count=$(ls -1 "${status_dir}" 2>/dev/null | wc -l | tr -d ' ')

        if [[ $ready_count -eq $total_services ]]; then
            log_info "âœ… æ‰€æœ‰ ${total_services} ä¸ªæœåŠ¡å·²å°±ç»ª"
            return 0
        fi

        log_info "---> ${ready_count}/${total_services} æœåŠ¡å°±ç»ªï¼Œç»§ç»­ç­‰å¾…... (å·²ç­‰å¾… ${total_wait_time}s)"
        sleep "$interval"
        total_wait_time=$((total_wait_time + interval))
    done

    log_warn "â° è¶…æ—¶: æœåŠ¡åœ¨ ${MAX_WAIT_TIME} ç§’å†…æœªå®Œå…¨å°±ç»ªï¼Œå°†ç»§ç»­ä½¿ç”¨å·²å°±ç»ªçš„æœåŠ¡"
}

# å°†æ•°æ®æ–‡ä»¶æŒ‰è½®è¯¢æ–¹å¼åˆ†é…åˆ°å„ä¸ªå®ä¾‹
# Args:
#   $1: total_instances (int) - æ€»å®ä¾‹æ•°é‡
# Returns:
#   None (åˆ†é…ç»“æœå­˜å‚¨åœ¨å…¨å±€å˜é‡ INSTANCE_ASSIGNMENTS_X ä¸­)
assign_data_to_instances() {
    local total_instances="$1"

    log_info "ğŸ“Š æ­£åœ¨åˆ†é…å…¨éƒ¨ ${#FILES[@]} ä¸ªæ•°æ®æ–‡ä»¶åˆ° ${total_instances} ä¸ªå®ä¾‹..."

    # é”€æ¯å¹¶åˆå§‹åŒ–å®ä¾‹åˆ†é…æ•°ç»„
    for ((i = 0; i < total_instances; i++)); do
        # åŠ¨æ€å£°æ˜/æ¸…ç©ºæ•°ç»„å˜é‡
        eval "INSTANCE_ASSIGNMENTS_$i=()"
    done

    # è½®è¯¢åˆ†é…æ–‡ä»¶
    for idx in "${!FILES[@]}"; do
        local file="${FILES[idx]}"
        local instance_idx=$((idx % total_instances))
        # åŠ¨æ€èµ‹å€¼æ•°ç»„å…ƒç´ 
        eval "INSTANCE_ASSIGNMENTS_${instance_idx}+=(\"\$file\")"
        log_info "åˆ†é…æ–‡ä»¶: ${file} -> å®ä¾‹ ${instance_idx}"
    done

    # æ‰“å°åˆ†é…ç»“æœç»Ÿè®¡
    for ((i = 0; i < total_instances; i++)); do
        local count
        eval "count=\${#INSTANCE_ASSIGNMENTS_${i}[@]}"
        log_info "å®ä¾‹ ${i} åˆ†é… ${count} ä¸ªæ–‡ä»¶"
    done

    log_info "âœ… æ•°æ®æ–‡ä»¶åˆ†é…å®Œæˆ"
}

# åœ¨æŒ‡å®šèŠ‚ç‚¹ä¸Šæ‰¹é‡æäº¤æ¨ç†ä»»åŠ¡ï¼ŒåŒ…å«é‡è¯•å’Œèµ„æºæ§åˆ¶æœºåˆ¶
# Args:
#   $1: node (string) - èŠ‚ç‚¹åœ°å€
#   $2: port (int) - æœåŠ¡ç«¯å£
#   $3: model_name (string) - æ¨¡å‹åç§°
#   $4: base_url (string) - æœåŠ¡ URL (å¦‚ http://127.0.0.1:port/v1)
#   $@: files (string array) - åˆ†é…ç»™è¯¥èŠ‚ç‚¹çš„å…¨éƒ¨æ–‡ä»¶åˆ—è¡¨
# Returns:
#   None (ä»»åŠ¡åœ¨è¿œç¨‹åå°å¯åŠ¨ï¼Œä¸ç­‰å¾…å®Œæˆ)
run_task_batch_parallel() {
    local node="$1"
    local port="$2"
    local model_name="$3"
    local base_url="$4"
    shift 4
    local files=("$@")

    log_info "ğŸ‘‰ åœ¨èŠ‚ç‚¹ ${node} ä¸Šå¯åŠ¨ ${#files[@]} ä¸ªæ¨ç†ä»»åŠ¡..."

    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶éœ€è¦å¤„ç†
    if [[ ${#files[@]} -eq 0 ]]; then
        log_warn "èŠ‚ç‚¹ ${node} æ²¡æœ‰åˆ†é…åˆ°ä»»ä½•æ–‡ä»¶ï¼Œè·³è¿‡ä»»åŠ¡å¯åŠ¨"
        return 0
    fi

    # æ„å»ºæ‰€æœ‰æ–‡ä»¶çš„æ¨ç†å‘½ä»¤å¹¶ä¸€æ¬¡æ€§å‘é€
    local commands=()
    for file in "${files[@]}"; do
        local input_file="${DATASET_DIR}/${file}"
        # ç§»é™¤æ–‡ä»¶æ‰©å±•å
        local base_name="${file%.*}"
        local output_file="${OUTPUT_DIR}/infer_${model_name//\//_}_${base_name}_bz${N_SAMPLES}.jsonl"
        local log_file="${LOG_DIR}/${TASK_LOG_PREFIX}${node//./_}_${base_name}.log"

        log_info "  -> å‡†å¤‡å¤„ç†æ–‡ä»¶: ${file} (è¾“å‡º: ${output_file})"

        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if ! ssh_run "$node" "test -f '${input_file}'" >/dev/null 2>&1; then
            log_error "âŒ è¾“å…¥æ–‡ä»¶ ${input_file} åœ¨èŠ‚ç‚¹ ${node} ä¸Šä¸å­˜åœ¨"
            continue
        fi

        # æ„å»ºæ¨ç†å‘½ä»¤
        local infer_cmd="cd '${PROJECT_DIR}' && \
            source '${SET_ENV_SCRIPT}' && \
            nohup python '${INFER_SCRIPT}' \
                --input_file '${input_file}' \
                --output_file '${output_file}' \
                --input_key '${INPUT_KEY}' \
                --base_url '${base_url}' \
                --model_name '${model_name}' \
                --n_samples ${N_SAMPLES} \
                --system_prompt_type '${SYSTEM_PROMPT_TYPE}' \
                --max_workers ${MAX_WORKERS} \
                > '${log_file}' 2>&1 &"

        commands+=("$infer_cmd")
    done

    # å°†æ‰€æœ‰å‘½ä»¤ç»„åˆæˆä¸€ä¸ªå‘½ä»¤å­—ç¬¦ä¸²å¹¶æ‰§è¡Œ
    if [[ ${#commands[@]} -gt 0 ]]; then
        local combined_cmd=$(printf "%s " "${commands[@]}")
        log_info "ğŸš€ èŠ‚ç‚¹ ${node} æäº¤ OpenAI API Server è¿›è¡Œæ¨ç†ä»»åŠ¡..."
        ssh_run "$node" "$combined_cmd" >/dev/null 2>&1
        # æ·»åŠ ä¸€ä¸ªå°å»¶è¿Ÿä»¥ç¡®ä¿ä»»åŠ¡æ­£ç¡®å¯åŠ¨
        sleep 2
    else
        log_warn "èŠ‚ç‚¹ ${node} ä¸Šæ²¡æœ‰æœ‰æ•ˆçš„æ¨ç†ä»»åŠ¡å‘½ä»¤ï¼Œè·³è¿‡æ‰§è¡Œ"
    fi

    # ç­‰å¾…ä»»åŠ¡å®Œæˆ
    wait_for_batch_completion_and_cleanup "$node" "$port" ${#commands[@]}
}

run_task_batch() {
    local node="$1"
    local model_name="$2"
    local base_url="$3"
    shift 3
    local files=("$@")

    log_info "ğŸ‘‰ åœ¨èŠ‚ç‚¹ ${node} ä¸Šå¯åŠ¨ ${#files[@]} ä¸ªæ¨ç†ä»»åŠ¡..."

    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶éœ€è¦å¤„ç†
    if [[ ${#files[@]} -eq 0 ]]; then
        log_warn "èŠ‚ç‚¹ ${node} æ²¡æœ‰åˆ†é…åˆ°ä»»ä½•æ–‡ä»¶ï¼Œè·³è¿‡ä»»åŠ¡å¯åŠ¨"
        return 0
    fi

    # é™åˆ¶å•ä¸ªèŠ‚ç‚¹ä¸ŠåŒæ—¶è¿è¡Œçš„æ¨ç†ä»»åŠ¡æ•°é‡
    local max_concurrent_tasks_per_node=${MAX_CONCURRENT_TASKS_PER_NODE:-8}
    local total_tasks=${#files[@]}

    # åˆ†æ‰¹å¤„ç†ä»»åŠ¡ä»¥æ§åˆ¶å¹¶å‘æ•°
    local batch_start=0
    while [[ $batch_start -lt $total_tasks ]]; do
        # è®¡ç®—å½“å‰æ‰¹æ¬¡å¤§å°
        local batch_end=$((batch_start + max_concurrent_tasks_per_node))
        if [[ $batch_end -gt $total_tasks ]]; then
            batch_end=$total_tasks
        fi

        log_info "å¤„ç†æ‰¹æ¬¡: ä» ${batch_start} åˆ° $((batch_end - 1)) (å…± $((batch_end - batch_start)) ä¸ªä»»åŠ¡)"

        # æ„å»ºå½“å‰æ‰¹æ¬¡çš„æ¨ç†å‘½ä»¤
        local commands=()
        for (( i=batch_start; i<batch_end; i++ )); do
            local file="${files[$i]}"
            local input_file="${DATASET_DIR}/${file}"
            # ç§»é™¤æ–‡ä»¶æ‰©å±•å
            local base_name="${file%.*}"
            local output_file="${OUTPUT_DIR}/infer_${model_name//\//_}_${base_name}_bz${N_SAMPLES}.jsonl"
            local log_file="${LOG_DIR}/${TASK_LOG_PREFIX}${node//./_}_${base_name}.log"

            log_info "  -> å‡†å¤‡å¤„ç†æ–‡ä»¶: ${file} (è¾“å‡º: ${output_file})"

            # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if ! ssh_run "$node" "test -f '${input_file}'" >/dev/null 2>&1; then
                log_error "âŒ è¾“å…¥æ–‡ä»¶ ${input_file} åœ¨èŠ‚ç‚¹ ${node} ä¸Šä¸å­˜åœ¨"
                continue
            fi

            # æ„å»ºæ¨ç†å‘½ä»¤
            local infer_cmd="cd '${PROJECT_DIR}' && \
                source '${SET_ENV_SCRIPT}' && \
                nohup python '${INFER_SCRIPT}' \
                    --input_file '${input_file}' \
                    --output_file '${output_file}' \
                    --input_key '${INPUT_KEY}' \
                    --base_url '${base_url}' \
                    --model_name '${model_name}' \
                    --n_samples ${N_SAMPLES} \
                    --system_prompt_type '${SYSTEM_PROMPT_TYPE}' \
                    --max_workers ${MAX_WORKERS} \
                    > '${log_file}' 2>&1 &"

            commands+=("$infer_cmd")
        done

        # å°†å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰å‘½ä»¤ç»„åˆæˆä¸€ä¸ªå‘½ä»¤å­—ç¬¦ä¸²å¹¶æ‰§è¡Œ
        if [[ ${#commands[@]} -gt 0 ]]; then
            local combined_cmd=$(printf "%s " "${commands[@]}")
            local remote_cmd="($combined_cmd) >/dev/null 2>&1 &"
            ssh_run "$node" "$remote_cmd"
            log_info "âœ… èŠ‚ç‚¹ ${node} ä¸Šçš„ ${#commands[@]} ä¸ªæ¨ç†ä»»åŠ¡å·²æäº¤"
        fi

        # ç­‰å¾…å½“å‰æ‰¹æ¬¡ä»»åŠ¡å®Œæˆ
        log_info "ç­‰å¾…å½“å‰æ‰¹æ¬¡ä»»åŠ¡å®Œæˆ..."
        wait_for_batch_completion "$node" ${#commands[@]}

        # ç§»åŠ¨åˆ°ä¸‹ä¸€æ‰¹æ¬¡
        batch_start=$batch_end
    done

    log_info "âœ… èŠ‚ç‚¹ ${node} ä¸Šçš„æ‰€æœ‰ ${#files[@]} ä¸ªæ¨ç†ä»»åŠ¡å·²å®Œæˆ"
}

# Args:
#   $1: node (string) - èŠ‚ç‚¹åœ°å€
#   $2: port (int) - æœåŠ¡ç«¯å£
#   $3: expected_count (int) - é¢„æœŸå®Œæˆçš„ä»»åŠ¡æ•°
# Returns:
#   None
wait_for_batch_completion_and_cleanup() {
    local node="$1"
    local port="$2"
    local expected_count="$3"
    local max_wait_time=864000  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰(10å¤©)
    local wait_interval=600     # æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    local total_wait_time=0

    log_info "â³ ç­‰å¾…èŠ‚ç‚¹ ${node} ä¸Šçš„ ${expected_count} ä¸ªä»»åŠ¡å®Œæˆ..."

    while [[ $total_wait_time -lt $max_wait_time ]]; do
        local current_running_tasks
        current_running_tasks=$(ssh_run "$node" "pgrep -f '${INFER_SCRIPT}' | wc -l" 2>/dev/null || echo "0")

        if [[ $current_running_tasks -le 0 ]]; then
            log_info "âœ… èŠ‚ç‚¹ ${node} ä¸Šçš„ ${expected_count} ä¸ªæ¨ç†ä»»åŠ¡å·²å®Œæˆ"

            # ä»»åŠ¡å®Œæˆåï¼Œåœæ­¢è¯¥èŠ‚ç‚¹çš„ vLLM æœåŠ¡
            log_info "ğŸ“‹ æ¨ç†ä»»åŠ¡å®Œæˆï¼Œæ­£åœ¨æ¸…ç†èµ„æº..."
            stop_service_on_node "$node" "$port"

            return 0
        fi

        log_info "â³ èŠ‚ç‚¹ ${node} ä¸Šä»æœ‰ ${current_running_tasks} ä¸ªä»»åŠ¡åœ¨è¿è¡Œï¼Œå·²ç­‰å¾… ${total_wait_time} ç§’"
        sleep $wait_interval
        total_wait_time=$((total_wait_time + wait_interval))
    done

    log_warn "â° ç­‰å¾…è¶…æ—¶ï¼ŒèŠ‚ç‚¹ ${node} ä¸Šçš„ä»»åŠ¡å¯èƒ½ä»åœ¨è¿è¡Œï¼Œå·²ç­‰å¾… ${total_wait_time} ç§’"
    # å³ä½¿è¶…æ—¶ï¼Œä»ç„¶å°è¯•åœæ­¢æœåŠ¡
    log_warn "æ­£åœ¨å¼ºåˆ¶åœæ­¢èŠ‚ç‚¹ ${node} ä¸Šçš„ vLLM æœåŠ¡..."
    stop_service_on_node "$node" "$port"
}

# åˆ†å‘å¹¶å¯åŠ¨æ‰€æœ‰æ¨ç†ä»»åŠ¡
# Args:
#   None
# Returns:
#   None
distribute_and_launch_jobs() {
    local total_instances=${#READY_INSTANCE_PORTS[@]}

    if [[ $total_instances -eq 0 ]]; then
        handle_error 1 "æ²¡æœ‰å¯ç”¨å®ä¾‹å¯ä¾›æ‰§è¡Œæ¨ç†ä»»åŠ¡"
    fi

    log_info "å¼€å§‹åˆ†å‘å¹¶å¯åŠ¨æ¨ç†ä»»åŠ¡..."

    # 1. åˆ†é…æ•°æ®æ–‡ä»¶åˆ°å¯ç”¨å®ä¾‹
    assign_data_to_instances "$total_instances"

    # 2. ä¸ºæ¯ä¸ªèŠ‚ç‚¹å¯åŠ¨å¯¹åº”çš„æ¨ç†ä»»åŠ¡ï¼ˆå¹¶è¡Œï¼‰
    local pids=()
    for ((i = 0; i < total_instances; i++)); do
        local node="${READY_INSTANCE_NODES[i]}"
        local port="${READY_INSTANCE_PORTS[i]}"
        # æ³¨æ„: vLLM OpenAI å…¼å®¹å±‚ API é€šå¸¸åœ¨ /v1 è·¯å¾„ä¸‹
        local base_url="http://127.0.0.1:${port}/v1"
        local model_name="${SERVED_MODEL_NAME}"

        # è·å–åˆ†é…ç»™å½“å‰å®ä¾‹çš„æ–‡ä»¶åˆ—è¡¨
        local instance_files_var="INSTANCE_ASSIGNMENTS_$i"
        local -n instance_files_ref="$instance_files_var"

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åˆ†é… (å¦‚æœ assign_data_to_instances ä¸­æœ‰èŠ‚ç‚¹æ²¡æœ‰åˆ†é…åˆ°æ–‡ä»¶ï¼Œè¿™é‡Œè·³è¿‡)
        if [[ ${#instance_files_ref[@]} -eq 0 ]]; then
            log_info "èŠ‚ç‚¹ ${node} æœªåˆ†é…åˆ°æ–‡ä»¶ï¼Œè·³è¿‡"
            continue
        fi
        # è·å–åˆ†é…ç»™å½“å‰å®ä¾‹çš„æ–‡ä»¶åˆ—è¡¨
        log_info "èŠ‚ç‚¹ ${node} åˆ†é…åˆ° ${#instance_files_ref[@]} ä¸ªæ–‡ä»¶"
        # åœ¨åå°å¯åŠ¨ä»»åŠ¡æäº¤æ‰¹æ¬¡
        (
            run_task_batch_parallel "$node" "$port" "$model_name" "$base_url" "${instance_files_ref[@]}"
        ) &
        pids+=($!)
    done

    # 3. ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹çš„ä»»åŠ¡æäº¤å®Œæˆï¼ˆä¸ç­‰å¾…è¿œç«¯å…·ä½“æ¨ç†å®Œæˆï¼‰
    if [[ ${#pids[@]} -gt 0 ]]; then
        wait "${pids[@]}" || true
    fi
    log_info "âœ… æ‰€æœ‰æ¨ç†ä»»åŠ¡å·²å¯åŠ¨ï¼Œè¿›å…¥è¿œç«¯ä»»åŠ¡ç›‘æ§é˜¶æ®µ, è¯·æŸ¥çœ‹æ¨ç†ç»“æœçš„è·¯å¾„: ${OUTPUT_DIR}"
}



# =======================================================
#                  ä¸»ç¨‹åºå…¥å£
# =======================================================

# ä¸»å‡½æ•°ï¼šåè°ƒæ•´ä¸ªéƒ¨ç½²å’Œæ¨ç†æµç¨‹
# Args:
#   $@: å‘½ä»¤è¡Œå‚æ•° (å¯é€‰: NODE_LIST_FILE)
# Returns:
#   None
main() {
    log_info " å¼€å§‹æ‰§è¡Œåˆ†å¸ƒå¼ vLLM æ¨¡å‹æ¨ç†éƒ¨ç½²"
    echo "================================================"

    # è®¾ç½®é€€å‡ºæ—¶çš„æ¸…ç†é™·é˜± (æœ€å…ˆè®¾ç½®ï¼Œç¡®ä¿ä»»ä½•å¤±è´¥éƒ½èƒ½è°ƒç”¨æ¸…ç†)
    trap 'cleanup_and_exit' EXIT TERM INT

    # éªŒè¯é…ç½®å‚æ•°
    validate_config

    # è·å–æ–‡ä»¶é”
    acquire_lock

    # å‚æ•°è§£æ
    if [[ $# -gt 1 ]]; then
        log_error "å‚æ•°é”™è¯¯"
        usage
    fi

    local NODE_LIST_FILE="${1:-./node_list_all.txt}"

    # éªŒè¯èŠ‚ç‚¹åˆ—è¡¨æ–‡ä»¶
    if [[ ! -f "$NODE_LIST_FILE" ]]; then
        handle_error 1 "èŠ‚ç‚¹åˆ—è¡¨æ–‡ä»¶ '${NODE_LIST_FILE}' ä¸å­˜åœ¨"
    fi

    log_info "ä»æ–‡ä»¶ '${NODE_LIST_FILE}' åŠ è½½èŠ‚ç‚¹åˆ—è¡¨"

    # è¯»å–èŠ‚ç‚¹åˆ—è¡¨ï¼ˆè¿‡æ»¤ç©ºè¡Œå’Œæ³¨é‡Šï¼‰ï¼Œå­˜å…¥å…¨å±€ NODES
    mapfile -t NODES < <(grep -v -e '^\s*$' -e '^\s*#' "$NODE_LIST_FILE")

    if [[ ${#NODES[@]} -eq 0 ]]; then
        handle_error 1 "èŠ‚ç‚¹åˆ—è¡¨ '${NODE_LIST_FILE}' ä¸ºç©º"
    fi

    log_info "å‘ç° ${#NODES[@]} ä¸ªèŠ‚ç‚¹: ${NODES[*]}"

    # è‡ªåŠ¨ç”Ÿæˆç«¯å£åˆ—è¡¨ï¼ˆèŠ‚ç‚¹é—´é—´éš” 10 ç«¯å£ï¼‰ï¼Œå­˜å…¥å…¨å±€ PORTS
    PORTS=()
    local start_port=6000
    for ((i=0; i<${#NODES[@]}; i++)); do
        PORTS+=($((start_port + i * 10)))
    done
    log_info "è‡ªåŠ¨ç”Ÿæˆç«¯å£åˆ—è¡¨: ${PORTS[*]}"

    # --- æ‰§è¡Œä¸»è¦æµç¨‹ ---
    log_info "å¼€å§‹æ‰§è¡Œéƒ¨ç½²æµç¨‹..."

    # æ­¥éª¤1: å‘ç°æ•°æ®é›†æ–‡ä»¶
    discover_remote_dataset_files

    # æ­¥éª¤2: æ£€æŸ¥èŠ‚ç‚¹ä¸ç«¯å£é…ç½®
    check_node_port_alignment

    # æ­¥éª¤3: å‡†å¤‡è¿œç¨‹ç›®å½•
    check_and_prepare_remote_dirs

    # æ­¥éª¤4: å¹¶è¡Œéƒ¨ç½²æ¨¡å‹æœåŠ¡
    log_info "æ­£åœ¨å¹¶è¡Œéƒ¨ç½²æ‰€æœ‰æ¨¡å‹æœåŠ¡..."
    for ((i = 0; i < ${#NODES[@]}; i++)); do
        local node="${NODES[i]}"
        local port="${PORTS[i]}"
        local instance_id=0
        # åœ¨æœ¬åœ°åå°éƒ¨ç½²ï¼ŒåŠ é€Ÿå¹¶å‘
        deploy_model_service "$node" "$port" "$instance_id" &
    done

    # ç­‰å¾…æ‰€æœ‰éƒ¨ç½²å‘½ä»¤å‘é€å®Œæˆ (å³ä½¿å¤±è´¥ï¼Œdeploy_model_service ä¹Ÿä¼šè¿”å›)
    wait || true

    # æ­¥éª¤5: ç­‰å¾…æœåŠ¡å°±ç»ªå¹¶è·å–å¯ç”¨èŠ‚ç‚¹ï¼ˆHTTP å¥åº·æ£€æŸ¥ + æ—¥å¿—å›é€€ï¼‰
    wait_for_services

    # ä¸å†ä½¿ç”¨ wait_for_services çš„è¿”å›å€¼ï¼Œè€Œæ˜¯ä¸»åŠ¨æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
    log_info "æ­£åœ¨æ£€æŸ¥å„èŠ‚ç‚¹æœåŠ¡çŠ¶æ€..."

    # åˆå§‹åŒ–å¯ç”¨èŠ‚ç‚¹å’Œå¤±è´¥èŠ‚ç‚¹åˆ—è¡¨
    READY_INSTANCE_NODES=()
    READY_INSTANCE_PORTS=()
    local -a failed_nodes=()
    local -a failed_ports=()

    # æ£€æŸ¥æ¯ä¸ªèŠ‚ç‚¹çš„çŠ¶æ€
    for ((i = 0; i < ${#NODES[@]}; i++)); do
        local node="${NODES[i]}"
        local port="${PORTS[i]}"
        # è·å–èŠ‚ç‚¹çš„ API æœåŠ¡çŠ¶æ€æ–‡ä»¶
        local status_file="${LOG_DIR}/status/status_${node//./_}.ok"

        if [[ -f "$status_file" ]]; then
            log_info "âœ… èŠ‚ç‚¹ ${node} (ç«¯å£: ${port}) æœåŠ¡å°±ç»ª"
            READY_INSTANCE_NODES+=("${node}")
            READY_INSTANCE_PORTS+=("${port}")
        else
            log_warn "âŒ èŠ‚ç‚¹ ${node} (ç«¯å£: ${port}) æœåŠ¡æœªå°±ç»ª"
            failed_nodes+=("${node}")
            failed_ports+=("${port}")
        fi
    done

    # è¾“å‡ºéƒ¨ç½²ç»“æœç»Ÿè®¡
    log_info "ğŸ“Š æœåŠ¡éƒ¨ç½²ç»“æœç»Ÿè®¡:"
    log_info "   - æˆåŠŸèŠ‚ç‚¹æ•°é‡: ${#READY_INSTANCE_NODES[@]}/${#NODES[@]}"

    if [[ ${#failed_nodes[@]} -gt 0 ]]; then
        log_warn "ä»¥ä¸‹èŠ‚ç‚¹æœªèƒ½æˆåŠŸéƒ¨ç½²:"
        for ((i = 0; i < ${#failed_nodes[@]}; i++)); do
            log_warn "   - ${failed_nodes[i]} (ç«¯å£: ${failed_ports[i]})"
        done
        log_warn "è¯·æ£€æŸ¥è¿™äº›èŠ‚ç‚¹çš„æ—¥å¿—æ–‡ä»¶: ${LOG_DIR}/${API_SERVER_LOG_PREFIX}<èŠ‚ç‚¹å>.log"
    fi

    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨èŠ‚ç‚¹
    if [[ ${#READY_INSTANCE_NODES[@]} -eq 0 ]]; then
        handle_error 1 "âŒ æ²¡æœ‰ä»»ä½•èŠ‚ç‚¹æˆåŠŸå¯åŠ¨æœåŠ¡ï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œæ¨ç†ä»»åŠ¡"
    fi

    log_info "å°†ä½¿ç”¨ ${#READY_INSTANCE_NODES[@]} ä¸ªå¯ç”¨èŠ‚ç‚¹è¿›è¡Œæ¨ç†"

    # æ­¥éª¤6: ä½¿ç”¨å¯ç”¨èŠ‚ç‚¹åˆ†å‘å¹¶å¯åŠ¨æ¨ç†ä»»åŠ¡
    distribute_and_launch_jobs
    # æ­¥éª¤7: ç­‰å¾…æ¨ç†ä»»åŠ¡å®Œæˆ
    # wait_for_inference_completion

    # æ­¥éª¤8: ä¼˜é›…å…³é—­æœåŠ¡ï¼ˆç”± EXIT é™·é˜±è°ƒç”¨ stop_servicesï¼‰
    log_info "âœ… åˆ†å¸ƒå¼æ¨ç†éƒ¨ç½²å’Œä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œæ­£åœ¨é€€å‡ºå¹¶æ¸…ç†èµ„æº..."

    log_info "ğŸ“Š éƒ¨ç½²ç»Ÿè®¡:"
    log_info "   - èŠ‚ç‚¹æ€»æ•°: ${#NODES[@]}"
    log_info "   - å¯ç”¨èŠ‚ç‚¹: ${#READY_INSTANCE_NODES[@]}"
    log_info "   - æ•°æ®æ–‡ä»¶: ${#FILES[@]}"
    log_info "   - è¾“å‡ºç›®å½•: ${OUTPUT_DIR}"
    log_info "   - æ—¥å¿—ç›®å½•: ${LOG_DIR}"
    echo "================================================"
}


# è„šæœ¬å…¥å£ç‚¹
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
