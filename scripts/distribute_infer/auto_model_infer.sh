#!/bin/bash
set -euo pipefail


# =======================================================
#                  è„šæœ¬é…ç½®
# =======================================================

# SSH é€‰é¡¹ï¼ˆæ›´å¿«æ›´ç¨³ï¼šè·³è¿‡æŒ‡çº¹äº¤äº’ã€è®¾ç½®è¶…æ—¶ã€è¿æ¥å¤ç”¨ï¼‰
readonly SSH_OPTS="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=5 -o ServerAliveInterval=30 -o ServerAliveCountMax=3 -o ControlMaster=auto -o ControlPersist=60s"
# å¦‚éœ€è‡ªå®šä¹‰ ssh ç”¨æˆ·ï¼šexport SSH_USER=rootï¼›é»˜è®¤ä½¿ç”¨å½“å‰ç”¨æˆ·
readonly SSH_USER="${SSH_USER:-}"

# === æ¨¡å‹ä¸èµ„æºå‚æ•° ===
readonly MODEL_PATH="/home/jianzhnie/llmtuner/hfhub/mindspeed/models/mindspore/hf_sft_packing_0703_step6476"
readonly NUM_GPUS=8
readonly MEMORY_UTILIZATION=0.9
readonly MAX_MODEL_LEN=65536
readonly N_SAMPLES=8            # æ¯ä¸ªæ ·æœ¬é‡å¤é‡‡æ ·æ¬¡æ•°
readonly SERVED_MODEL_NAME="PCL-Reasoner"
# Ascend è®¾å¤‡å¯è§æ€§ï¼ˆæ ¹æ® NUM_GPUS è‡ªåŠ¨ç”Ÿæˆ 0..N-1ï¼‰
readonly ASCEND_VISIBLE=$(seq -s, 0 $((NUM_GPUS-1)))

# === é¡¹ç›®ä¸è„šæœ¬è·¯å¾„ï¼ˆç¡®ä¿è¿œç¨‹èŠ‚ç‚¹ä¸æœ¬æœºä¸€è‡´ï¼‰===
readonly PROJECT_DIR="/home/jianzhnie/llmtuner/llm/LLMEval"
readonly INFER_SCRIPT="${PROJECT_DIR}/llmeval/vllm/online_server.py"
readonly SET_ENV_SCRIPT="${PROJECT_DIR}/set_env.sh"

# === è¾“å‡ºä¸æ—¥å¿—ç›®å½•ï¼ˆåœ¨è¿œç¨‹èŠ‚ç‚¹ä¸Šåˆ›å»ºä¸å†™å…¥ï¼‰===
readonly OUTPUT_ROOT="/home/jianzhnie/llmtuner/llm/LLMEval/output"
readonly OUTPUT_DIR="${OUTPUT_ROOT}/$SERVED_MODEL_NAME"
readonly LOG_DIR="${OUTPUT_ROOT}/logs-rl"
mkdir -p ${OUTPUT_DIR}
# ä»…æ¸…ç†æœ¬åœ°æ®‹ç•™ç›®å½•ï¼ˆé¿å…å¹²æ‰°æœ¬åœ°çŠ¶æ€æ–‡ä»¶ï¼‰ï¼›è¿œç¨‹æ¸…ç†ä¼šåœ¨åç»­ä¸“é—¨æ‰§è¡Œ
rm -rf ${LOG_DIR}
mkdir -p ${LOG_DIR}
readonly API_SERVER_LOG_PREFIX="api_server_"
readonly TASK_LOG_PREFIX="task_"
readonly MAX_WAIT_TIME=900

# === æ•°æ®é›†ç›¸å…³ï¼ˆæ•°æ®å·²åœ¨è¿œç¨‹å„èŠ‚ç‚¹åŒæ­¥ï¼Œè‡ªåŠ¨å‘ç°æ–‡ä»¶ï¼‰===
readonly DATASET_DIR="${PROJECT_DIR}/data_process/model_infer"  # è¿œç¨‹èŠ‚ç‚¹ä¸Šçš„æ•°æ®ç›®å½•
# è‡ªåŠ¨å‘ç°çš„æ•°æ®æ–‡ä»¶é€šé…ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰ï¼Œæ”¯æŒ part1 å’Œ part_001 ç­‰ä¸¤ç§å‘½å
readonly DATASET_GLOB="${DATASET_GLOB:-top_100K_final_verified_samples_shard*}"
# å¹¶å‘åº¦é™åˆ¶ï¼ˆèŠ‚ç‚¹ä»»åŠ¡æäº¤æ—¶æœ¬åœ° wait çš„èŠ‚æµï¼‰
readonly MAX_JOBS=8

# rsync é€‰é¡¹ï¼ˆå¦‚æœ‰éœ€è¦å¯å¤ç”¨ï¼›å½“å‰é€»è¾‘ä¸å†ä¸»åŠ¨ä¸‹å‘æ•°æ®ï¼‰
readonly RSYNC_OPTS="-avz --checksum --partial --inplace --no-whole-file --exclude='.*'"

# å¯é€‰ï¼šæ¨ç†å®¢æˆ·ç«¯é¢å¤–å‚æ•°ï¼ˆæŒ‰éœ€å¯ç”¨ï¼‰
readonly SYSTEM_PROMPT_TYPE="${SYSTEM_PROMPT_TYPE:-empty}"
readonly MAX_WORKERS="${MAX_WORKERS:-8}"

# =======================================================
#                  å·¥å…·å‡½æ•°
# =======================================================

# æ‰“å°å¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º
usage() {
    echo "Usage: $0 [NODE_LIST_FILE]"
    echo
    echo "è·¨å¤šèŠ‚ç‚¹è‡ªåŠ¨éƒ¨ç½² vLLM å¹¶åˆ†å¸ƒå¼æ¨ç†ã€‚"
    echo
    echo "Arguments:"
    echo "  NODE_LIST_FILE    åŒ…å«èŠ‚ç‚¹ IP æˆ–ä¸»æœºåçš„æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./node_list_all.txt)"
    echo "                    æ–‡ä»¶å†…æ¯è¡Œä¸€ä¸ªèŠ‚ç‚¹ï¼Œæ”¯æŒ # æ³¨é‡Šä¸ç©ºè¡Œã€‚"
    exit 1
}

# ç»Ÿä¸€çš„ SSH æ‰§è¡Œå°è£…ï¼ˆè‡ªåŠ¨æ‹¼æ¥ user@hostï¼‰
ssh_run() {
    local node="$1"
    shift
    local userhost="${SSH_USER:+${SSH_USER}@}${node}"
    ssh ${SSH_OPTS} "${userhost}" "$@"
}

# å°†æœ¬åœ°æ–‡ä»¶é€šè¿‡ rsync åŒæ­¥åˆ°è¿œç¨‹ï¼ˆå½“å‰æœªä½¿ç”¨ï¼Œä¿ç•™ä»¥å¤‡æ‰©å±•ï¼‰
rsync_to_node() {
    local src_path="$1"   # æœ¬åœ°ç»å¯¹æˆ–ç›¸å¯¹è·¯å¾„
    local node="$2"
    local dst_path="$3"   # è¿œç¨‹ç»å¯¹è·¯å¾„
    local userhost="${SSH_USER:+${SSH_USER}@}${node}"
    rsync ${RSYNC_OPTS} "${src_path}" "${userhost}:${dst_path}"
}

# =======================================================
#                  æ ¸å¿ƒå‡½æ•°åŒº
# =======================================================

# æ£€æŸ¥èŠ‚ç‚¹ä¸ç«¯å£åˆ—è¡¨æ˜¯å¦å¯¹é½
check_node_port_alignment() {
  if [[ ${#NODES[@]} -ne ${#PORTS[@]} ]]; then
        echo "âŒ é”™è¯¯: NODES (${#NODES[@]}) ä¸ PORTS (${#PORTS[@]}) æ•°é‡ä¸ä¸€è‡´ã€‚" >&2
        exit 1
  fi
    echo "âœ… èŠ‚ç‚¹å’Œç«¯å£é…ç½®æ£€æŸ¥é€šè¿‡ã€‚"
}

# åœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä¸Šå‘ç°æ•°æ®é›†æ–‡ä»¶ï¼ˆç»“æœç”¨äºæ‰€æœ‰èŠ‚ç‚¹ä»»åŠ¡åˆ†é…ï¼‰
discover_remote_dataset_files() {
    if [[ ${#NODES[@]} -eq 0 ]]; then
        echo "âŒ é”™è¯¯: æ— èŠ‚ç‚¹å¯ç”¨äºå‘ç°æ•°æ®æ–‡ä»¶ã€‚" >&2
        exit 1
    fi
    local head_node="${NODES[0]}"
    echo "ğŸ” æ­£åœ¨ ${head_node} ä¸Šå‘ç°æ•°æ®æ–‡ä»¶ï¼š${DATASET_DIR}/${DATASET_GLOB}"
    # ä»…åˆ—åï¼ˆbasenameï¼‰ï¼Œå¹¶è¿›è¡Œè‡ªç„¶æ•°å€¼æ’åºï¼ˆæ”¯æŒ part_2 < part_10 çš„æ­£ç¡®é¡ºåºï¼‰
    local out
    if ! out=$(ssh_run "$head_node" "sh -lc 'ls -1 ${DATASET_DIR}/${DATASET_GLOB} 2>/dev/null | xargs -n1 basename | LC_ALL=C sort -V'"); then
        echo "âŒ é”™è¯¯: æ— æ³•åœ¨ ${head_node} ä¸Šåˆ—å‡ºæ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ä¸æƒé™ã€‚" >&2
        exit 1
    fi
    mapfile -t FILES < <(printf "%s\n" "$out" || true)
    if [[ ${#FILES[@]} -eq 0 ]]; then
        echo "âŒ é”™è¯¯: æœªå‘ç°ä»»ä½•åŒ¹é…çš„æ•°æ®æ–‡ä»¶ï¼ˆglob: ${DATASET_GLOB}ï¼‰ã€‚" >&2
        exit 1
    fi
    echo "âœ… å‘ç°æ•°æ®é›†æ–‡ä»¶æ•°é‡ï¼š${#FILES[@]}"
}

# æ£€æŸ¥å¹¶åˆ›å»ºè¿œç¨‹è¾“å‡ºä¸æ•°æ®ç›®å½•ï¼ˆå¹¶æ¸…ç†è¿œç¨‹æ—¥å¿—ç›®å½•ï¼Œç¡®ä¿æœ¬æ¬¡è¿è¡Œå¹²å‡€ï¼‰
check_and_prepare_remote_dirs() {
    echo "âš™ï¸ æ­£åœ¨æ£€æŸ¥å¹¶åˆ›å»ºè¿œç¨‹ç›®å½•ï¼Œå¹¶æ¸…ç†æ—§æ—¥å¿—..."
    for node in "${NODES[@]}"; do
        ssh_run "$node" "mkdir -p '${OUTPUT_DIR}' '${DATASET_DIR}' && rm -rf '${LOG_DIR}' && mkdir -p '${LOG_DIR}'" || {
            echo "âŒ é”™è¯¯ï¼šæ— æ³•åœ¨èŠ‚ç‚¹ ${node} ä¸Šå‡†å¤‡ç›®å½•æˆ–éªŒè¯è·¯å¾„ã€‚è¯·æ£€æŸ¥SSHè¿æ¥å’Œæƒé™ã€‚" >&2
            exit 1
        }
    done
    echo "âœ… æ‰€æœ‰è¿œç¨‹ç›®å½•å·²å°±ç»ªï¼Œæ—¥å¿—å·²æ¸…ç†ã€‚"
}


# åœæ­¢æ‰€æœ‰éƒ¨ç½²åœ¨è¿œç¨‹èŠ‚ç‚¹çš„æ¨¡å‹æœåŠ¡
stop_services() {
    echo "ğŸ›‘ è„šæœ¬é€€å‡ºï¼Œæ­£åœ¨å°è¯•åœæ­¢æ‰€æœ‰è¿œç¨‹æ¨¡å‹æœåŠ¡..."
    local search_pattern="vllm.entrypoints.openai.api_server"
    for node in "${NODES[@]}"; do
        echo "   -> æ­£åœ¨åœæ­¢ ${node} ä¸Šçš„ vLLM è¿›ç¨‹..."
        ssh_run "$node" "pkill -f '${search_pattern}' || true" &
    done
    wait || true
    echo "âœ… æ‰€æœ‰è¿œç¨‹æ¨¡å‹æœåŠ¡åœæ­¢å®Œæˆã€‚"
}

# éƒ¨ç½²å•ä¸ª vLLM æ¨¡å‹æœåŠ¡åˆ°æŸèŠ‚ç‚¹
deploy_model_service() {
    local node=$1
    local port=$2
    local log_file="${LOG_DIR}/${API_SERVER_LOG_PREFIX}${node//./_}.log"

    echo "ğŸš€ åœ¨èŠ‚ç‚¹ ${node} ä¸Šéƒ¨ç½²æ¨¡å‹ï¼Œç«¯å£ ${port}. (TP=${NUM_GPUS}, mem_util=${MEMORY_UTILIZATION})"

    ssh_run "$node" "cd '${PROJECT_DIR}' && \
        source '${SET_ENV_SCRIPT}' && \
        export ASCEND_RT_VISIBLE_DEVICES='${ASCEND_VISIBLE}' && \
        nohup python -m vllm.entrypoints.openai.api_server \
            --model '${MODEL_PATH}' \
            --trust-remote-code \
            --served-model-name '${SERVED_MODEL_NAME}' \
            --tensor-parallel-size ${NUM_GPUS} \
            --gpu-memory-utilization ${MEMORY_UTILIZATION} \
            --max-model-len ${MAX_MODEL_LEN} \
            --enforce-eager \
            --port ${port} > '${log_file}' 2>&1 &" &
}

# è½®è¯¢æ£€æŸ¥æ‰€æœ‰æ¨¡å‹æœåŠ¡æ˜¯å¦å¯åŠ¨æˆåŠŸï¼ˆé€šè¿‡è¿œç¨‹æ—¥å¿—å…³é”®å­—ï¼‰
wait_for_services() {
    echo "â³ æ­£åœ¨ç­‰å¾…æ‰€æœ‰æ¨¡å‹æœåŠ¡å¯åŠ¨å¹¶å°±ç»ª... æœ€é•¿ç­‰å¾… ${MAX_WAIT_TIME} ç§’ã€‚"
    local total_wait_time=0
    local interval=10
    local total_services=${#NODES[@]}
    local status_dir="${LOG_DIR}/status"

    rm -rf "${status_dir}" || true
    mkdir -p "${status_dir}"
    while [ "$total_wait_time" -lt "$MAX_WAIT_TIME" ]; do
        local running_pids=()

        for ((i = 0; i < total_services; i++)); do
            local node=${NODES[i]}
            local port=${PORTS[i]}
            local log_file="${LOG_DIR}/${API_SERVER_LOG_PREFIX}${node//./_}.log"
            local status_file="${status_dir}/status_${node//./_}.ok"

            if [ -f "$status_file" ]; then
                continue
            fi

            (
                if ssh_run "$node" "grep -q 'Application startup complete.' '${log_file}'"; then
                    echo "âœ… æœåŠ¡ ${node}:${port} å·²å°±ç»ª (æ—¥å¿—ç¡®è®¤)."
                    touch "$status_file"
                fi
            ) &
            running_pids+=($!)
        done

        if [ ${#running_pids[@]} -gt 0 ]; then
            wait "${running_pids[@]}"
        fi

        local ready_count
        ready_count=$(ls -1 "${status_dir}" 2>/dev/null | wc -l | tr -d ' ')

        if [ "$ready_count" -eq "$total_services" ]; then
            echo "âœ… All ${total_services} services ready."
            return 0
        fi

        echo "    -> ${ready_count}/${total_services} ready. Waiting..."
        sleep "$interval"
        total_wait_time=$((total_wait_time + interval))
    done

    echo "âŒ Timeout: services not ready in ${MAX_WAIT_TIME}s. Check remote logs."
    exit 1
}

# å°†æ•°æ®(æ–‡ä»¶åˆ—è¡¨)æŒ‰è½®è¯¢åˆ†é…åˆ° N ä¸ªå®ä¾‹ï¼ˆN=èŠ‚ç‚¹æ•°ï¼‰
assign_data_to_instances() {
    local total_instances="$1"
    for ((i = 0; i < total_instances; i++)); do
        eval "INSTANCE_ASSIGNMENTS_$i=()"
    done

    for idx in "${!FILES[@]}"; do
        local file=${FILES[idx]}
        local instance_idx=$((idx % total_instances))
        eval "INSTANCE_ASSIGNMENTS_${instance_idx}+=(\"\$file\")"
        echo "Assign ${file} -> instance ${instance_idx}"
    done
}

# åœ¨æŸèŠ‚ç‚¹ä¸Šæ‰¹é‡æäº¤æ¨ç†ä»»åŠ¡ï¼ˆæ¯ä¸ªæ–‡ä»¶ä¸€ä¸ªåå°ä»»åŠ¡ï¼‰
run_task_batch() {
    local node=$1
    local model_name=$2
    local base_url=$3
    shift 3
    local files=("$@")

    echo "ğŸ‘‰ Starting tasks on node: $node with model $model_name"

    for file in "${files[@]}"; do
        local input_file="${DATASET_DIR}/${file}"
        local base_name=$(basename "$file" .jsonl)
        local output_file="${OUTPUT_DIR}/infer_${model_name//\//_}_${base_name}_bz${N_SAMPLES}.jsonl"
        local log_file="${LOG_DIR}/${TASK_LOG_PREFIX}${node//./_}_${base_name}.log"

        echo "ğŸ‘‰ Running inference on ${file} using ${model_name} at ${base_url}"

        ssh_run "$node" "cd '${PROJECT_DIR}' && \
        source '${SET_ENV_SCRIPT}' && \
            nohup python '${INFER_SCRIPT}' \
            --input_file '${input_file}' \
            --output_file '${output_file}' \
            --input_key "question" \
            --base_url '${base_url}' \
            --model_name '${model_name}' \
            --n_samples ${N_SAMPLES} \
            --system_prompt_type '${SYSTEM_PROMPT_TYPE}' \
            --max_workers ${MAX_WORKERS} > '${log_file}' 2>&1 &" &
    done
}

# æ ¹æ®èŠ‚ç‚¹æ•°é‡åˆ†å‘å¹¶æäº¤ä»»åŠ¡
distribute_and_launch_jobs() {
    local total_instances=${#NODES[@]}
    assign_data_to_instances "$total_instances"

    local in_flight=0
    for ((i = 0; i < total_instances; i++)); do
        local node=${NODES[i]}
        local port=${PORTS[i]}
        local base_url="http://127.0.0.1:${port}/v1"
        local model_name="${SERVED_MODEL_NAME}"

        IFS=$'\n' read -r -d '' -a ASSIGNED < <(eval "printf '%s\0' \"\${INSTANCE_ASSIGNMENTS_${i}[@]}\"")
        # è‹¥è¯¥èŠ‚ç‚¹æœ¬è½®æœªåˆ†é…åˆ°ä»»ä½•æ–‡ä»¶ï¼Œåˆ™è·³è¿‡
        if [[ ${#ASSIGNED[@]} -eq 0 ]]; then
            continue
        fi

        run_task_batch "$node" "$model_name" "$base_url" "${ASSIGNED[@]:-}"

        in_flight=$((in_flight + 1))
        if [ $in_flight -ge $MAX_JOBS ]; then
            wait
            in_flight=0
        fi
    done

    wait
    echo "âœ… All inference jobs launched."
}

# =======================================================
#                  ä¸»æµç¨‹
# =======================================================
main() {

    # ========== è¯»å–èŠ‚ç‚¹åˆ—è¡¨å¹¶é…ç½®ç«¯å£ ==========
    if [ "$#" -gt 1 ]; then
        echo "âŒ é”™è¯¯: å‚æ•°è¿‡å¤šã€‚"
        usage
    fi

    local NODE_LIST_FILE="${1:-"./node_list_all.txt"}"

    if [ ! -f "$NODE_LIST_FILE" ]; then
        echo "âŒ é”™è¯¯: èŠ‚ç‚¹åˆ—è¡¨æ–‡ä»¶ '${NODE_LIST_FILE}' ä¸å­˜åœ¨ï¼" >&2
        usage
    fi

    echo "âœ… ä»æ–‡ä»¶ '${NODE_LIST_FILE}' åŠ è½½èŠ‚ç‚¹åˆ—è¡¨ã€‚"
    mapfile -t NODES < <(grep -v -e '^\s*$' -e '^\s*#' "$NODE_LIST_FILE")

    if [ ${#NODES[@]} -eq 0 ]; then
        echo "âŒ é”™è¯¯: èŠ‚ç‚¹åˆ—è¡¨ '${NODE_LIST_FILE}' ä¸ºç©ºã€‚"
        exit 1
    fi

    PORTS=()
    local start_port=6000
    for ((i=0; i<${#NODES[@]}; i++)); do
        PORTS+=($((start_port + i * 10)))
    done
    echo "âœ… è‡ªåŠ¨ç”Ÿæˆç«¯å£åˆ—è¡¨ï¼š${PORTS[@]}"

    # è®¾ç½®æ¸…ç†é™·é˜±ï¼Œç¡®ä¿é€€å‡ºæ—¶å…³é—­æ‰€æœ‰è¿œç¨‹ vLLM
    trap stop_services EXIT

    # è‡ªåŠ¨å‘ç°æ•°æ®é›†æ–‡ä»¶ï¼ˆåœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä¸Šæ‰«æï¼‰
    discover_remote_dataset_files

    # æ­¥éª¤1: æ£€æŸ¥èŠ‚ç‚¹ä¸ç«¯å£å¯¹é½
    check_node_port_alignment

    # æ­¥éª¤2: åˆ›å»ºè¿œç¨‹ç›®å½•å¹¶æ¸…ç†æ—¥å¿—
    # check_and_prepare_remote_dirs

    # æ­¥éª¤4: åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå¹¶è¡Œéƒ¨ç½²æ¨¡å‹æœåŠ¡
    echo "ğŸ”„ æ­£åœ¨å¹¶è¡Œéƒ¨ç½²æ‰€æœ‰æ¨¡å‹æœåŠ¡..."
    for ((i = 0; i < ${#NODES[@]}; i++)); do
        local node=${NODES[i]}
        local port=${PORTS[i]}
        deploy_model_service "$node" "$port"
    done

    # æ­¥éª¤5: è½®è¯¢æ£€æŸ¥æ‰€æœ‰æœåŠ¡æ˜¯å¦å°±ç»ª
    wait_for_services

    # æ­¥éª¤6: åˆ†é…æ•°æ®é›†å¹¶å¹¶è¡Œå¯åŠ¨æ¨ç†ä»»åŠ¡
    distribute_and_launch_jobs
}

# è¿è¡Œä¸»å‡½æ•°
main "$@"
